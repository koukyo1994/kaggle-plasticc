{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "from multiprocessing import Pool\n",
    "tqdm.pandas(desc=\"apply progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/hidehisa/.kaggle/competitions/plasticc\"\n",
    "train = pd.read_csv(data_dir + \"/train_with_cluster.csv\")\n",
    "meta = pd.read_csv(data_dir + \"/training_set_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic(d):\n",
    "    df = d.copy()\n",
    "    df[\"flux_ratio_sq\"] = np.power(df[\"flux\"] / df[\"flux_err\"], 2)\n",
    "    df[\"flux_by_flux_ratio_sq\"] = df[\"flux\"] * df[\"flux_ratio_sq\"]\n",
    "\n",
    "    aggs = {\n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'detected': ['mean'],\n",
    "        'flux_ratio_sq': ['sum', 'skew'],\n",
    "        'flux_by_flux_ratio_sq': ['sum', 'skew'],\n",
    "    }\n",
    "    agg_df = df.groupby('object_id').agg(aggs)\n",
    "    new_columns = [k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "    agg_df.columns = new_columns\n",
    "    agg_df['flux_diff'] = agg_df['flux_max'] - agg_df['flux_min']\n",
    "    agg_df['flux_dif2'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_mean']\n",
    "    agg_df['flux_w_mean'] = agg_df['flux_by_flux_ratio_sq_sum'] / agg_df[\n",
    "        'flux_ratio_sq_sum']\n",
    "    agg_df['flux_dif3'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_w_mean']\n",
    "    \n",
    "    \n",
    "    per_passband_aggs = {\n",
    "        \"flux\": [\"min\", \"max\", \"mean\", \"std\"],\n",
    "        \"flux_ratio_sq\": [\"sum\", \"skew\"],\n",
    "        \"flux_by_flux_ratio_sq\": [\"sum\", \"skew\"]\n",
    "    }\n",
    "    per_pass_agg_df = df.groupby([\"object_id\", \"passband\"]).agg(per_passband_aggs)\n",
    "    per_pass_agg_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in per_pass_agg_df.columns])\n",
    "    per_pass_agg_df[\"flux_diff\"] = per_pass_agg_df[\"flux_max\"] - per_pass_agg_df[\"flux_min\"]\n",
    "    per_pass_agg_df[\"flux_diff2\"] = (\n",
    "        per_pass_agg_df[\"flux_max\"] - per_pass_agg_df[\"flux_min\"]) / per_pass_agg_df[\"flux_mean\"]\n",
    "    per_pass_agg_df[\"flux_w_mean\"] = per_pass_agg_df[\"flux_by_flux_ratio_sq_sum\"] / per_pass_agg_df[\n",
    "        \"flux_ratio_sq_sum\"\n",
    "    ]\n",
    "    per_pass_agg_df[\"flux_dif3\"] = (\n",
    "    per_pass_agg_df[\"flux_max\"] - per_pass_agg_df[\"flux_min\"]) / per_pass_agg_df[\"flux_w_mean\"]\n",
    "    per_pass_agg_df = per_pass_agg_df.unstack()\n",
    "    per_pass_agg_df.columns = pd.Index([str(e[1]) + \"__\" + e[0] for e in per_pass_agg_df.columns])\n",
    "    \n",
    "    basic_columns = [f\"{i}__{j}\" for i in range(6) for j in [\n",
    "        \"flux_min\",\n",
    "        \"flux_max\",\n",
    "        \"flux_mean\",\n",
    "        \"flux_std\",\n",
    "        \"flux_ratio_sq_sum\",\n",
    "        \"flux_ratio_sq_skew\",\n",
    "        \"flux_w_mean\",\n",
    "        \"flux_diff2\"\n",
    "    ]]\n",
    "    per_pass_agg_df.drop(basic_columns, axis=1, inplace=True)\n",
    "    \n",
    "    agg_df = pd.merge(agg_df, per_pass_agg_df, how=\"left\", on=\"object_id\")\n",
    "    \n",
    "    agg_flux_diff = agg_df.reset_index()[[\"object_id\", \"flux_diff\"]]\n",
    "    df2 = pd.merge(df, agg_df, how=\"left\", on=\"object_id\")\n",
    "    df2[\"flux_norm\"] = df2.flux / df2.flux_diff\n",
    "    del df2[\"flux\"]\n",
    "    fcp = {\n",
    "        'fft_coefficient': [{\n",
    "            'coeff': 0,\n",
    "            'attr': 'abs'\n",
    "        }, {\n",
    "            'coeff': 1,\n",
    "            'attr': 'abs'\n",
    "        }],\n",
    "        'kurtosis':\n",
    "        None,\n",
    "        'skewness':\n",
    "        None,\n",
    "        \"cid_ce\": [{\"normalize\": True}]\n",
    "    }\n",
    "    fcp2 = {\n",
    "        \"fft_coefficient\": [{\n",
    "            \"coeff\": 0,\n",
    "            \"attr\": \"abs\"\n",
    "        }, {\n",
    "            \"coeff\": 1,\n",
    "            \"attr\": \"abs\"\n",
    "        }],\n",
    "        \"abs_energy\": None,\n",
    "        \"sample_entropy\": None\n",
    "    }\n",
    "    fcp_flux = {\n",
    "        \"longest_strike_above_mean\": None,\n",
    "        \"longest_strike_below_mean\": None,\n",
    "        \"mean_change\": None,\n",
    "        \"mean_abs_change\": None,\n",
    "        \"cid_ce\": [{\"normalize\": True}]\n",
    "    }\n",
    "    fcp_flux_by_flux_ratio_sq = {\n",
    "        \"longest_strike_above_mean\": None,\n",
    "        \"longest_strike_below_mean\": None\n",
    "    }\n",
    "    agg_df_ts = extract_features(\n",
    "        df,\n",
    "        column_id='object_id',\n",
    "        column_sort='mjd',\n",
    "        column_kind='passband',\n",
    "        column_value='flux',\n",
    "        default_fc_parameters=fcp,\n",
    "        n_jobs=6)\n",
    "    agg_df_ts2 = extract_features(\n",
    "        df2,\n",
    "        column_id=\"object_id\",\n",
    "        column_sort=\"mjd\",\n",
    "        column_kind=\"passband\",\n",
    "        column_value=\"flux_norm\",\n",
    "        default_fc_parameters=fcp2,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    agg_df_flux = extract_features(\n",
    "        df,\n",
    "        column_id=\"object_id\",\n",
    "        column_value=\"flux\",\n",
    "        default_fc_parameters=fcp_flux,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    agg_df_ffrs = extract_features(\n",
    "        df,\n",
    "        column_id=\"object_id\",\n",
    "        column_value=\"flux_by_flux_ratio_sq\",\n",
    "        default_fc_parameters=fcp_flux_by_flux_ratio_sq,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    df_det = df[df['detected'] == 1].copy()\n",
    "\n",
    "    agg_df_mjd = extract_features(\n",
    "        df_det,\n",
    "        column_id='object_id',\n",
    "        column_value='mjd',\n",
    "        default_fc_parameters={\n",
    "            'maximum': None,\n",
    "            'minimum': None\n",
    "        },\n",
    "        n_jobs=8)\n",
    "    agg_df_mjd['mjd_diff_det'] = agg_df_mjd['mjd__maximum'] - agg_df_mjd[\n",
    "        'mjd__minimum']\n",
    "    del agg_df_mjd['mjd__maximum'], agg_df_mjd['mjd__minimum']\n",
    "    agg_df_ts2.columns = pd.Index([e + \"_norm\" for e in agg_df_ts2.columns])\n",
    "    agg_df_ts = pd.merge(agg_df_ts, agg_df_mjd, on='id')\n",
    "    agg_df_ts = pd.merge(agg_df_ts, agg_df_ts2, on=\"id\")\n",
    "    agg_df_ts = pd.merge(agg_df_ts, agg_df_flux, on=\"id\")\n",
    "    agg_df_ts = pd.merge(agg_df_ts, agg_df_ffrs, on=\"id\")\n",
    "    # tsfresh returns a dataframe with an index name='id'\n",
    "    agg_df_ts.index.rename('object_id', inplace=True)\n",
    "    agg_df = pd.merge(agg_df, agg_df_ts, on='object_id')\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "def cluster_mean_diff(df):\n",
    "    new_df = df.groupby([\"object_id\", \"cluster\"]).agg({\n",
    "        \"flux\": [\"mean\", \"max\", \"min\"]\n",
    "    })\n",
    "    new_df.columns = pd.Index(\n",
    "        [e[0] + \"_\" + e[1] for e in new_df.columns.tolist()])\n",
    "    new_df[\"normalized_mean\"] = new_df[\"flux_mean\"] / (\n",
    "        new_df[\"flux_max\"] - new_df[\"flux_min\"])\n",
    "    new_df.reset_index(inplace=True)\n",
    "    return new_df.groupby(\"object_id\").agg({\"normalized_mean\": \"std\"})\n",
    "\n",
    "\n",
    "def passband_std_difference(df):\n",
    "    std_df = df.groupby([\"object_id\", \"cluster\", \"passband\"]).agg({\n",
    "        \"flux\": \"std\"\n",
    "    }).reset_index().groupby([\"object_id\",\n",
    "                              \"passband\"])[\"flux\"].mean().reset_index()\n",
    "    std_df_max = std_df.groupby(\"object_id\")[\"flux\"].max()\n",
    "    std_df_min = std_df.groupby(\"object_id\")[\"flux\"].min()\n",
    "    return (std_df_max / std_df_min).reset_index()\n",
    "\n",
    "\n",
    "def num_outliers(df):\n",
    "    new_df = df.groupby(\"object_id\").agg({\"flux\": [\"mean\", \"std\"]})\n",
    "    new_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in new_df.columns])\n",
    "    new_df[\"upper_sigma\"] = new_df[\"flux_mean\"] + new_df[\"flux_std\"]\n",
    "    new_df[\"upper_2sigma\"] = new_df[\"flux_mean\"] + 2 * new_df[\"flux_std\"]\n",
    "    new_df[\"lower_sigma\"] = new_df[\"flux_mean\"] - new_df[\"flux_std\"]\n",
    "    new_df[\"lower_2sigma\"] = new_df[\"flux_mean\"] - 2 * new_df[\"flux_std\"]\n",
    "    new_df.drop([\"flux_mean\", \"flux_std\"], axis=1, inplace=True)\n",
    "    new_df = pd.merge(df, new_df, how=\"left\", on=\"object_id\")\n",
    "    new_df[\"outside_sigma\"] = (\n",
    "        (new_df[\"flux\"] > new_df[\"upper_sigma\"]) |\n",
    "        (new_df[\"flux\"] < new_df[\"lower_sigma\"])).astype(int)\n",
    "    new_df[\"outside_2sigma\"] = (\n",
    "        (new_df[\"flux\"] > new_df[\"upper_2sigma\"]) |\n",
    "        (new_df[\"flux\"] < new_df[\"lower_2sigma\"])).astype(int)\n",
    "\n",
    "    return_df = new_df.groupby(\"object_id\").agg({\n",
    "        \"outside_sigma\": \"sum\",\n",
    "        \"outside_2sigma\": \"sum\"\n",
    "    })\n",
    "    return_df.reset_index(inplace=True)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_plus(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees) from \n",
    "    #https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "    \"\"\"\n",
    "    #Convert decimal degrees to Radians:\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon2 = np.radians(lon2)\n",
    "    lat2 = np.radians(lat2)\n",
    "\n",
    "    #Implementing Haversine Formula: \n",
    "    dlon = np.subtract(lon2, lon1)\n",
    "    dlat = np.subtract(lat2, lat1)\n",
    "\n",
    "    a = np.add(np.power(np.sin(np.divide(dlat, 2)), 2),  \n",
    "                          np.multiply(np.cos(lat1), \n",
    "                                      np.multiply(np.cos(lat2), \n",
    "                                                  np.power(np.sin(np.divide(dlon, 2)), 2))))\n",
    "    \n",
    "    haversine = np.multiply(2, np.arcsin(np.sqrt(a)))\n",
    "    return {\n",
    "        'haversine': haversine, \n",
    "        'latlon1': np.subtract(np.multiply(lon1, lat1), np.multiply(lon2, lat2)), \n",
    "   }\n",
    "\n",
    "\n",
    "def process_meta(meta_df):\n",
    "    meta_dict = dict()\n",
    "    # distance\n",
    "    meta_dict.update(haversine_plus(meta_df['ra'].values, meta_df['decl'].values, \n",
    "                   meta_df['gal_l'].values, meta_df['gal_b'].values))\n",
    "    #\n",
    "    meta_dict['hostgal_photoz_certain'] = np.multiply(\n",
    "            meta_df['hostgal_photoz'].values, \n",
    "             np.exp(meta_df['hostgal_photoz_err'].values))\n",
    "    \n",
    "    meta_df = pd.concat([meta_df, pd.DataFrame(meta_dict, index=meta_df.index)], axis=1)\n",
    "    return meta_df\n",
    "\n",
    "\n",
    "def add_rank_bottom_and_top(df, feature_name):\n",
    "    objid = [\"object_id\"]\n",
    "    columns = [f\"{i}{feature_name}\" for i in range(6)]\n",
    "    partial = df[objid+columns]\n",
    "    partial_values = partial.melt(id_vars=objid, value_vars=columns).sort_values([\"object_id\", \"value\"])\n",
    "    \n",
    "    top_and_bottom = partial_values.groupby(\"object_id\").agg({\n",
    "        \"variable\": [\"first\", \"last\"]\n",
    "    })\n",
    "    top_and_bottom.columns = [\"top\"+feature_name, \"bottom\"+feature_name]\n",
    "    for i, n in zip([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], columns):\n",
    "        top_and_bottom = top_and_bottom.replace(n, i)\n",
    "    top_and_bottom = top_and_bottom.astype(int)\n",
    "    return top_and_bottom\n",
    "\n",
    "\n",
    "def rank(df, feature_name, thres=20):\n",
    "    objid = [\"object_id\"]\n",
    "    columns = [f\"{i}{feature_name}\" for i in range(6)]\n",
    "    partial = df[objid+columns]\n",
    "    partial_values = partial.melt(id_vars=objid, value_vars=columns).sort_values([\"object_id\", \"value\"])\n",
    "    for i, n in zip([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], columns):\n",
    "        partial_values.replace(n, i, inplace=True)\n",
    "    partial_values[\"dummy\"] = 1\n",
    "    rank_feats = partial_values.groupby([\"object_id\", \"dummy\"]).agg({\n",
    "        \"variable\": \"sum\"\n",
    "    })\n",
    "    d = dict()\n",
    "    cnt = 0\n",
    "    for i in rank_feats[\"variable\"]:\n",
    "        if i not in d.keys():\n",
    "            d[i] = cnt\n",
    "            cnt += 1\n",
    "    rank_feats.reset_index(inplace=True)\n",
    "    rank_feats.drop(\"dummy\", axis=1, inplace=True)\n",
    "    rank_feats.rename(columns={\"variable\": f\"rank{feature_name}\"}, inplace=True)\n",
    "    rank_feats[f\"rank{feature_name}\"].replace(d, inplace=True)\n",
    "    rank_dict = (rank_feats[f\"rank{feature_name}\"].value_counts() > thres).to_dict()\n",
    "    rank_feats[f\"rank{feature_name}\"] = rank_feats[f\"rank{feature_name}\"].map(\n",
    "        lambda x: x if rank_dict[x] else cnt+1\n",
    "    )\n",
    "    \n",
    "    return rank_feats\n",
    "\n",
    "\n",
    "def add_by_features(df, feature_name, new_feat_name):\n",
    "    for i in range(5):\n",
    "        for j in range(1, 6):\n",
    "            if j > i:\n",
    "                df[f\"{new_feat_name}{j}_by_{i}\"] = df[f\"{j}{feature_name}\"] / df[f\"{i}{feature_name}\"]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_per_passband(d):\n",
    "    df = d.copy()\n",
    "    df[\"flux_ratio_sq\"] = np.power(df[\"flux\"] / df[\"flux_err\"], 2)\n",
    "    df[\"flux_by_flux_ratio_sq\"] = df[\"flux\"] * df[\"flux_ratio_sq\"]\n",
    "    per_passband_aggs = {\n",
    "        \"flux\": [\"min\", \"max\", \"mean\", \"std\"],\n",
    "        \"flux_ratio_sq\": [\"sum\", \"skew\"],\n",
    "        \"flux_by_flux_ratio_sq\": [\"sum\", \"skew\"]\n",
    "    }\n",
    "    per_pass_agg_df = df.groupby([\"object_id\", \"passband\"]).agg(per_passband_aggs)\n",
    "    per_pass_agg_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in per_pass_agg_df.columns])\n",
    "    per_pass_agg_df[\"flux_diff\"] = per_pass_agg_df[\"flux_max\"] - per_pass_agg_df[\"flux_min\"]\n",
    "    per_pass_agg_df[\"flux_diff2\"] = (\n",
    "        per_pass_agg_df[\"flux_max\"] - per_pass_agg_df[\"flux_min\"]) / per_pass_agg_df[\"flux_mean\"]\n",
    "    per_pass_agg_df[\"flux_w_mean\"] = per_pass_agg_df[\"flux_by_flux_ratio_sq_sum\"] / per_pass_agg_df[\n",
    "        \"flux_ratio_sq_sum\"\n",
    "    ]\n",
    "    per_pass_agg_df[\"flux_dif3\"] = (\n",
    "    per_pass_agg_df[\"flux_max\"] - per_pass_agg_df[\"flux_min\"]) / per_pass_agg_df[\"flux_w_mean\"]\n",
    "    per_pass_agg_df = per_pass_agg_df.unstack()\n",
    "    per_pass_agg_df.columns = pd.Index([str(e[1]) + \"__\" + e[0] for e in per_pass_agg_df.columns])\n",
    "    basic_columns = [f\"{i}__{j}\" for i in range(6) for j in [\n",
    "        \"flux_min\",\n",
    "        \"flux_max\",\n",
    "        \"flux_mean\",\n",
    "        \"flux_std\",\n",
    "        \"flux_ratio_sq_sum\",\n",
    "        \"flux_ratio_sq_skew\",\n",
    "        \"flux_w_mean\",\n",
    "        \"flux_diff2\"\n",
    "    ]]\n",
    "    per_pass_agg_df.drop(basic_columns, axis=1, inplace=True)\n",
    "    return per_pass_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full(df, meta):\n",
    "    agg_basic = basic(df)\n",
    "    cl_mean_diff = cluster_mean_diff(df)\n",
    "    ps_std_diff = passband_std_difference(df)\n",
    "    num_out = num_outliers(df)\n",
    "\n",
    "    full = pd.merge(agg_basic, cl_mean_diff, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, ps_std_diff, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(agg_basic, num_out, how=\"left\", on=\"object_id\")\n",
    "    meta = process_meta(meta)\n",
    "    full = pd.merge(full, meta, how=\"left\", on=\"object_id\")\n",
    "    full = add_by_features(full, \"__fft_coefficient__coeff_0__attr_\\\"abs\\\"_norm\", \"flux_norm_fft_\")\n",
    "    full = add_by_features(full, \"__abs_energy_norm\", \"abs_energy_\")\n",
    "    full = add_by_features(full, \"__flux_diff\", \"flux_diff_\")\n",
    "    abs_en_rank = rank(full, \"__abs_energy_norm\", 0)\n",
    "    flux_dif_rank = rank(full, \"__flux_diff\")\n",
    "    \n",
    "    flux_diff = add_rank_bottom_and_top(full, \"__flux_diff\")\n",
    "    flux_dif3 = add_rank_bottom_and_top(full, \"__flux_dif3\")\n",
    "    full = pd.merge(full, abs_en_rank, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, flux_dif_rank, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, flux_diff, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, flux_dif3, how=\"left\", on=\"object_id\")\n",
    "    if \"target\" in full.columns:\n",
    "        full.drop(\"target\", axis=1, inplace=True)\n",
    "    return full\n",
    "\n",
    "\n",
    "def train_data(df, meta):\n",
    "    full = get_full(df, meta)\n",
    "    y = meta.target\n",
    "    classes = sorted(y.unique())\n",
    "    class_weight = {c: 1 for c in classes}\n",
    "\n",
    "    for c in [64, 15]:\n",
    "        class_weight[c] = 2\n",
    "    oof_df = full[[\"object_id\"]]\n",
    "    del full['object_id'], full['distmod'], full['hostgal_specz']\n",
    "    del full['ra'], full['decl'], full['gal_l'], full['gal_b'], full['ddf']\n",
    "    return full, y, classes, class_weight, oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 30/30 [00:05<00:00,  5.92it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:15<00:00,  2.88it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:01<00:00, 17.80it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:00<00:00, 22.68it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 101.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.9 s, sys: 1.98 s, total: 35.8 s\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full, y, classes, class_weight, oof_df = train_data(train, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>flux_skew</th>\n",
       "      <th>flux_err_min</th>\n",
       "      <th>flux_err_max</th>\n",
       "      <th>flux_err_mean</th>\n",
       "      <th>flux_err_median</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_diff_5_by_2</th>\n",
       "      <th>flux_diff_4_by_3</th>\n",
       "      <th>flux_diff_5_by_3</th>\n",
       "      <th>flux_diff_5_by_4</th>\n",
       "      <th>rank__abs_energy_norm</th>\n",
       "      <th>rank__flux_diff</th>\n",
       "      <th>top__flux_diff</th>\n",
       "      <th>bottom__flux_diff</th>\n",
       "      <th>top__flux_dif3</th>\n",
       "      <th>bottom__flux_dif3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-123.096998</td>\n",
       "      <td>-89.477524</td>\n",
       "      <td>394.109851</td>\n",
       "      <td>-0.349540</td>\n",
       "      <td>2.130510</td>\n",
       "      <td>12.845472</td>\n",
       "      <td>4.482743</td>\n",
       "      <td>3.835268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619088</td>\n",
       "      <td>0.823590</td>\n",
       "      <td>0.820379</td>\n",
       "      <td>0.996101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14.735178</td>\n",
       "      <td>14.770886</td>\n",
       "      <td>-1.423351</td>\n",
       "      <td>-0.873033</td>\n",
       "      <td>6.471144</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.639458</td>\n",
       "      <td>9.115748</td>\n",
       "      <td>2.359620</td>\n",
       "      <td>1.998217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407103</td>\n",
       "      <td>0.932131</td>\n",
       "      <td>1.221587</td>\n",
       "      <td>1.310531</td>\n",
       "      <td>1</td>\n",
       "      <td>548</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.159811</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>2.267434</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>8.022239</td>\n",
       "      <td>3.177854</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>11.281384</td>\n",
       "      <td>2.471061</td>\n",
       "      <td>1.990851</td>\n",
       "      <td>...</td>\n",
       "      <td>2.787751</td>\n",
       "      <td>1.204789</td>\n",
       "      <td>1.704010</td>\n",
       "      <td>1.414364</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.494463</td>\n",
       "      <td>220.795212</td>\n",
       "      <td>8.909206</td>\n",
       "      <td>1.035895</td>\n",
       "      <td>27.558208</td>\n",
       "      <td>4.979826</td>\n",
       "      <td>0.567170</td>\n",
       "      <td>55.892746</td>\n",
       "      <td>2.555576</td>\n",
       "      <td>1.819875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680688</td>\n",
       "      <td>0.956449</td>\n",
       "      <td>0.728946</td>\n",
       "      <td>0.762138</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-16.543753</td>\n",
       "      <td>143.600189</td>\n",
       "      <td>7.145702</td>\n",
       "      <td>1.141288</td>\n",
       "      <td>20.051722</td>\n",
       "      <td>4.406298</td>\n",
       "      <td>0.695277</td>\n",
       "      <td>11.383690</td>\n",
       "      <td>2.753004</td>\n",
       "      <td>2.214854</td>\n",
       "      <td>...</td>\n",
       "      <td>1.103552</td>\n",
       "      <td>1.122882</td>\n",
       "      <td>0.841532</td>\n",
       "      <td>0.749439</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      flux_min    flux_max   flux_mean  flux_median    flux_std  flux_skew  \\\n",
       "0 -1100.440063  660.626343 -123.096998   -89.477524  394.109851  -0.349540   \n",
       "1   -14.735178   14.770886   -1.423351    -0.873033    6.471144   0.014989   \n",
       "2   -19.159811   47.310059    2.267434     0.409172    8.022239   3.177854   \n",
       "3   -15.494463  220.795212    8.909206     1.035895   27.558208   4.979826   \n",
       "4   -16.543753  143.600189    7.145702     1.141288   20.051722   4.406298   \n",
       "\n",
       "   flux_err_min  flux_err_max  flux_err_mean  flux_err_median  \\\n",
       "0      2.130510     12.845472       4.482743         3.835268   \n",
       "1      0.639458      9.115748       2.359620         1.998217   \n",
       "2      0.695106     11.281384       2.471061         1.990851   \n",
       "3      0.567170     55.892746       2.555576         1.819875   \n",
       "4      0.695277     11.383690       2.753004         2.214854   \n",
       "\n",
       "         ...          flux_diff_5_by_2  flux_diff_4_by_3  flux_diff_5_by_3  \\\n",
       "0        ...                  0.619088          0.823590          0.820379   \n",
       "1        ...                  1.407103          0.932131          1.221587   \n",
       "2        ...                  2.787751          1.204789          1.704010   \n",
       "3        ...                  0.680688          0.956449          0.728946   \n",
       "4        ...                  1.103552          1.122882          0.841532   \n",
       "\n",
       "   flux_diff_5_by_4  rank__abs_energy_norm  rank__flux_diff  top__flux_diff  \\\n",
       "0          0.996101                      0                0               0   \n",
       "1          1.310531                      1              548               2   \n",
       "2          1.414364                      2                2               1   \n",
       "3          0.762138                      3                3               0   \n",
       "4          0.749439                      4                4               0   \n",
       "\n",
       "   bottom__flux_diff  top__flux_dif3  bottom__flux_dif3  \n",
       "0                  1               0                  1  \n",
       "1                  0               5                  1  \n",
       "2                  5               4                  0  \n",
       "3                  2               1                  5  \n",
       "4                  4               3                  0  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean = full.mean(axis=0)\n",
    "full.fillna(0, inplace=True)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {\n",
    "        6: 1,\n",
    "        15: 2,\n",
    "        16: 1,\n",
    "        42: 1,\n",
    "        52: 1,\n",
    "        53: 1,\n",
    "        62: 1,\n",
    "        64: 2,\n",
    "        65: 1,\n",
    "        67: 1,\n",
    "        88: 1,\n",
    "        90: 1,\n",
    "        92: 1,\n",
    "        95: 1\n",
    "    }\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array(\n",
    "        [class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = -np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lgb_multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {\n",
    "        6: 1,\n",
    "        15: 2,\n",
    "        16: 1,\n",
    "        42: 1,\n",
    "        52: 1,\n",
    "        53: 1,\n",
    "        62: 1,\n",
    "        64: 2,\n",
    "        65: 1,\n",
    "        67: 1,\n",
    "        88: 1,\n",
    "        90: 1,\n",
    "        92: 1,\n",
    "        95: 1\n",
    "    }\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n",
    "\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array(\n",
    "        [class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = -np.sum(y_w) / np.sum(class_arr)\n",
    "    return 'wloss', loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_importances(importances_):\n",
    "    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n",
    "    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    sns.barplot(\n",
    "        x='gain',\n",
    "        y='feature',\n",
    "        data=importances_.sort_values('mean_gain', ascending=False)[:500])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig('importances_12.png')\n",
    "\n",
    "    \n",
    "def importances_difference(importances_list):\n",
    "    n = len(importances_list)\n",
    "    imps = []\n",
    "    for imp in importances_list:\n",
    "        i = imp.copy()\n",
    "        mean_gain = i[[\"gain\", \"feature\"]].groupby(\"feature\").mean()\n",
    "        i[\"mean_gain\"] = i[\"feature\"].map(mean_gain[\"gain\"])\n",
    "        i.sort_values(\"mean_gain\", ascending=False, inplace=True)\n",
    "        i.reset_index(inplace=True)\n",
    "        im = i.groupby(\"feature\").agg({\n",
    "            \"mean_gain\": \"mean\"\n",
    "        }).sort_values(\"mean_gain\", ascending=False).reset_index()\n",
    "        imps.append(im)\n",
    "    swap_count = dict()\n",
    "    for i in range(n-1):\n",
    "        for j in range(1, n):\n",
    "            left = imps[i][\"feature\"].to_frame(\"feature\")\n",
    "            right = imps[j][\"feature\"].to_frame(\"feature\")\n",
    "            l_eq_r = (left == right)\n",
    "            l_neq_r = left[~l_eq_r].dropna()[\"feature\"].reset_index()\n",
    "            l_neq_r = l_neq_r[\"feature\"]\n",
    "            for s in l_neq_r:\n",
    "                left_ind = left.query(f\"feature == '{s}'\").index[0]\n",
    "                right_ind = right.query(f\"feature == '{s}'\").index[0]\n",
    "                dif = abs(left_ind - right_ind)\n",
    "                if s in swap_count.keys():\n",
    "                    swap_count[s] += dif\n",
    "                else:\n",
    "                    swap_count[s] = dif\n",
    "    return swap_count\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def save_cm(y, oof_preds, path):\n",
    "    unique_y = np.unique(y)\n",
    "    class_map = dict()\n",
    "    for i, val in enumerate(unique_y):\n",
    "        class_map[val] = i\n",
    "\n",
    "    y_map = np.zeros((y.shape[0], ))\n",
    "    y_map = np.array([class_map[val] for val in y])\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_map, np.argmax(oof_preds, axis=-1))\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    sample_sub = pd.read_csv(path)\n",
    "    class_names = list(sample_sub.columns[1:-1])\n",
    "    del sample_sub\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plot_confusion_matrix(\n",
    "        cnf_matrix,\n",
    "        classes=class_names,\n",
    "        normalize=True,\n",
    "        title='Confusion matrix')\n",
    "    plt.savefig(\"confusion_matrix_12.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_(full, seed=7):\n",
    "    folds = StratifiedKFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "    clfs = []\n",
    "    importances = pd.DataFrame()\n",
    "\n",
    "    lgb_params = {\n",
    "        'device': 'cpu', \n",
    "        'objective': 'multiclass', \n",
    "        'num_class': 14, \n",
    "        'boosting_type': 'gbdt', \n",
    "        'n_jobs': -1, \n",
    "        'max_depth': 7, \n",
    "        'n_estimators': 500, \n",
    "        'subsample_freq': 2, \n",
    "        'subsample_for_bin': 5000, \n",
    "        'min_data_per_group': 100, \n",
    "        'max_cat_to_onehot': 4, \n",
    "        'cat_l2': 1.0, \n",
    "        'cat_smooth': 59.5, \n",
    "        'max_cat_threshold': 32, \n",
    "        'metric_freq': 10, \n",
    "        'verbosity': -1, \n",
    "        'metric': 'multi_logloss', \n",
    "        'xgboost_dart_mode': False, \n",
    "        'uniform_drop': False, \n",
    "        'colsample_bytree': 0.5, \n",
    "        'drop_rate': 0.173, \n",
    "        'learning_rate': 0.0267, \n",
    "        'max_drop': 5, \n",
    "        'min_child_samples': 10, \n",
    "        'min_child_weight': 100.0, \n",
    "        'min_split_gain': 0.1, \n",
    "        'num_leaves': 7, \n",
    "        'reg_alpha': 0.1, \n",
    "        'reg_lambda': 0.00023, \n",
    "        'skip_drop': 0.44, \n",
    "        'subsample': 0.75\n",
    "    }\n",
    "\n",
    "    # Compute weights\n",
    "    w = y.value_counts()\n",
    "    weights = {i: np.sum(w) / w[i] for i in w.index}\n",
    "    oof_preds = np.zeros((len(full), np.unique(y).shape[0]))\n",
    "\n",
    "    for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "        trn_x, trn_y = full.iloc[trn_], y.iloc[trn_]\n",
    "        val_x, val_y = full.iloc[val_], y.iloc[val_]\n",
    "\n",
    "        clf = lgb.LGBMClassifier(**lgb_params)\n",
    "        clf.fit(\n",
    "            trn_x,\n",
    "            trn_y,\n",
    "            eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "            eval_metric=lgb_multi_weighted_logloss,\n",
    "            verbose=0,\n",
    "            early_stopping_rounds=50,\n",
    "            sample_weight=trn_y.map(weights),\n",
    "            categorical_feature=[\n",
    "                \"top__flux_diff\",\n",
    "                \"bottom__flux_diff\",\n",
    "                \"top__flux_dif3\",\n",
    "                \"bottom__flux_dif3\",\n",
    "                \"rank__abs_energy_norm\",\n",
    "                \"rank__flux_diff\"\n",
    "            ]\n",
    "        )\n",
    "        oof_preds[val_, :] = clf.predict_proba(\n",
    "            val_x, num_iteration=clf.best_iteration_)\n",
    "        print(multi_weighted_logloss(val_y, oof_preds[val_, :]))\n",
    "\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = full.columns\n",
    "        imp_df['gain'] = clf.feature_importances_\n",
    "        imp_df['fold'] = fold_ + 1\n",
    "        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "        clfs.append(clf)\n",
    "\n",
    "    print('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(\n",
    "        y_true=y, y_preds=oof_preds))\n",
    "    return clfs, multi_weighted_logloss(y_true=y, y_preds=oof_preds), importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_av_feature_selection(features, seeds=[1,3,5,7,9]):\n",
    "    clfs_ = []\n",
    "    losses = []\n",
    "    importances_ = []\n",
    "    for s in seeds:\n",
    "        clfs, loss, imp = model_(features, s)\n",
    "        clfs_.append(clfs)\n",
    "        losses.append(loss)\n",
    "        importances_.append(imp)\n",
    "    return clfs_, losses, importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5649913574729096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5839812690306275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6502814417139066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6130291253598786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5780451980607566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6019343913177286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.589156214364805\n",
      "MULTI WEIGHTED LOG LOSS : 0.59689 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5587842001930594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5568785740222109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6378971675335371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644252996204965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5668641686205359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5571420854861374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6475441269040506\n",
      "MULTI WEIGHTED LOG LOSS : 0.59466 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5350460369381114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5915900682038309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5654996834338687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6250669147505714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6466375740630442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6154013387495766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603360446345206\n",
      "MULTI WEIGHTED LOG LOSS : 0.59705 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5727464368021081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5495586298622177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859430303820174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52286559425233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5896437260830808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5903948816392256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6483852949343699\n",
      "MULTI WEIGHTED LOG LOSS : 0.59361 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6552596005334128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5445248638067991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6062441825062087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5540591980598735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5562872163500523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429086639149421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['bottom__flux_dif3', 'bottom__flux_diff', 'rank__abs_energy_norm', 'rank__flux_diff', 'top__flux_dif3', 'top__flux_diff']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5822853443708872\n",
      "MULTI WEIGHTED LOG LOSS : 0.59244 \n"
     ]
    }
   ],
   "source": [
    "clfs_, losses, importances_ = seed_av_feature_selection(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5968855043904381,\n",
       " 0.5946564896722112,\n",
       " 0.5970475518410397,\n",
       " 0.5936062448776385,\n",
       " 0.5924357672034836]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5966267414444344,\n",
       " 0.5952393653544562,\n",
       " 0.5939921878107963,\n",
       " 0.5928415708850884,\n",
       " 0.5941972363620499]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5945859518709558,\n",
       " 0.5965429277654001,\n",
       " 0.5952108103720704,\n",
       " 0.5952867012997356,\n",
       " 0.5922100086488644]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = importances_difference(importances_)\n",
    "sorted(dif.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4__fft_coefficient__coeff_0__attr_\"abs\"', 154),\n",
       " ('flux_norm_fft_5_by_1', 154),\n",
       " ('5__flux_dif3', 128),\n",
       " ('3__flux_dif3', 126),\n",
       " ('flux_diff_2_by_0', 124),\n",
       " ('flux_diff_4_by_0', 120),\n",
       " ('flux_norm_fft_5_by_2', 108),\n",
       " ('flux__longest_strike_below_mean', 106),\n",
       " ('flux_norm_fft_3_by_0', 104),\n",
       " ('flux_diff_1_by_0', 104),\n",
       " ('latlon1', 104),\n",
       " ('abs_energy_2_by_0', 100),\n",
       " ('4__fft_coefficient__coeff_1__attr_\"abs\"_norm', 100),\n",
       " ('abs_energy_3_by_0', 98),\n",
       " ('abs_energy_5_by_3', 98),\n",
       " ('flux_norm_fft_4_by_0', 96),\n",
       " ('abs_energy_1_by_0', 96),\n",
       " ('abs_energy_5_by_2', 92),\n",
       " ('abs_energy_5_by_1', 90),\n",
       " ('1__fft_coefficient__coeff_1__attr_\"abs\"', 88),\n",
       " ('flux_norm_fft_4_by_3', 86),\n",
       " ('0__fft_coefficient__coeff_1__attr_\"abs\"', 86),\n",
       " ('2__fft_coefficient__coeff_1__attr_\"abs\"_norm', 84),\n",
       " ('2__flux_diff', 80),\n",
       " ('4__skewness', 78),\n",
       " ('0__kurtosis', 78),\n",
       " ('abs_energy_3_by_2', 76),\n",
       " ('1__flux_dif3', 74),\n",
       " ('4__sample_entropy_norm', 74),\n",
       " ('0__fft_coefficient__coeff_1__attr_\"abs\"_norm', 72),\n",
       " ('flux_err_mean', 72),\n",
       " ('flux_diff_4_by_1', 72),\n",
       " ('abs_energy_5_by_4', 70),\n",
       " ('2__sample_entropy_norm', 68),\n",
       " ('flux_err_std', 68),\n",
       " ('2__flux_by_flux_ratio_sq_skew', 68),\n",
       " ('outside_sigma', 68),\n",
       " ('abs_energy_4_by_3', 66),\n",
       " ('1__abs_energy_norm', 64),\n",
       " ('flux_norm_fft_4_by_1', 64),\n",
       " ('1__fft_coefficient__coeff_1__attr_\"abs\"_norm', 64),\n",
       " ('flux_norm_fft_5_by_0', 64),\n",
       " ('flux_min', 62),\n",
       " ('abs_energy_3_by_1', 62),\n",
       " ('1__flux_by_flux_ratio_sq_sum', 62),\n",
       " ('flux_w_mean', 60),\n",
       " ('flux_diff_5_by_0', 60),\n",
       " ('flux_ratio_sq_sum', 60),\n",
       " ('4__flux_by_flux_ratio_sq_skew', 58),\n",
       " ('0__sample_entropy_norm', 58),\n",
       " ('flux_norm_fft_5_by_3', 58),\n",
       " ('flux_err_skew', 58),\n",
       " ('flux_norm_fft_2_by_1', 56),\n",
       " ('0__skewness', 56),\n",
       " ('flux_dif3', 56),\n",
       " ('flux_diff_4_by_2', 54),\n",
       " ('5__skewness', 54),\n",
       " ('4__fft_coefficient__coeff_1__attr_\"abs\"', 54),\n",
       " ('5__fft_coefficient__coeff_0__attr_\"abs\"_norm', 54),\n",
       " ('flux_err_median', 54),\n",
       " ('flux_by_flux_ratio_sq__longest_strike_above_mean', 52),\n",
       " ('5__fft_coefficient__coeff_1__attr_\"abs\"', 52),\n",
       " ('abs_energy_2_by_1', 52),\n",
       " ('0__flux_by_flux_ratio_sq_skew', 52),\n",
       " ('flux_diff_4_by_3', 50),\n",
       " ('flux__mean_change', 50),\n",
       " ('abs_energy_4_by_2', 50),\n",
       " ('top__flux_dif3', 50),\n",
       " ('2__flux_dif3', 48),\n",
       " ('5__fft_coefficient__coeff_0__attr_\"abs\"', 48),\n",
       " ('0__abs_energy_norm', 48),\n",
       " ('flux_max', 48),\n",
       " ('flux_diff', 48),\n",
       " ('4__fft_coefficient__coeff_0__attr_\"abs\"_norm', 48),\n",
       " ('abs_energy_4_by_1', 46),\n",
       " ('2__abs_energy_norm', 46),\n",
       " ('2__fft_coefficient__coeff_1__attr_\"abs\"', 44),\n",
       " ('3__flux_by_flux_ratio_sq_skew', 44),\n",
       " ('flux_diff_5_by_1', 44),\n",
       " ('1__flux_by_flux_ratio_sq_skew', 42),\n",
       " ('2__fft_coefficient__coeff_0__attr_\"abs\"_norm', 42),\n",
       " ('haversine', 42),\n",
       " ('4__flux_diff', 42),\n",
       " ('mwebv', 42),\n",
       " ('0__flux_by_flux_ratio_sq_sum', 40),\n",
       " ('5__flux_diff', 40),\n",
       " ('0__flux_dif3', 40),\n",
       " ('0__flux_diff', 40),\n",
       " ('flux_err_max', 40),\n",
       " ('flux_std', 40),\n",
       " ('abs_energy_4_by_0', 40),\n",
       " ('flux_norm_fft_3_by_2', 40),\n",
       " ('flux_ratio_sq_skew', 38),\n",
       " ('5__flux_by_flux_ratio_sq_skew', 38),\n",
       " ('flux_norm_fft_4_by_2', 38),\n",
       " ('4__abs_energy_norm', 38),\n",
       " ('flux_diff_3_by_1', 36),\n",
       " ('3__sample_entropy_norm', 36),\n",
       " ('flux_norm_fft_5_by_4', 36),\n",
       " ('bottom__flux_dif3', 34),\n",
       " ('2__cid_ce__normalize_True', 32),\n",
       " ('flux_diff_3_by_2', 32),\n",
       " ('5__sample_entropy_norm', 32),\n",
       " ('flux_diff_3_by_0', 32),\n",
       " ('flux_norm_fft_1_by_0', 32),\n",
       " ('3__fft_coefficient__coeff_1__attr_\"abs\"_norm', 30),\n",
       " ('1__skewness', 28),\n",
       " ('5__cid_ce__normalize_True', 28),\n",
       " ('5__kurtosis', 28),\n",
       " ('rank__abs_energy_norm', 28),\n",
       " ('flux_norm_fft_3_by_1', 28),\n",
       " ('4__flux_dif3', 28),\n",
       " ('4__flux_by_flux_ratio_sq_sum', 28),\n",
       " ('bottom__flux_diff', 26),\n",
       " ('0__fft_coefficient__coeff_0__attr_\"abs\"_norm', 26),\n",
       " ('abs_energy_5_by_0', 26),\n",
       " ('flux_mean', 26),\n",
       " ('3__fft_coefficient__coeff_0__attr_\"abs\"', 26),\n",
       " ('4__cid_ce__normalize_True', 24),\n",
       " ('1__sample_entropy_norm', 24),\n",
       " ('3__cid_ce__normalize_True', 24),\n",
       " ('5__flux_by_flux_ratio_sq_sum', 24),\n",
       " ('3__fft_coefficient__coeff_0__attr_\"abs\"_norm', 24),\n",
       " ('1__cid_ce__normalize_True', 22),\n",
       " ('flux__mean_abs_change', 22),\n",
       " ('0__cid_ce__normalize_True', 22),\n",
       " ('flux_diff_5_by_2', 22),\n",
       " ('5__fft_coefficient__coeff_1__attr_\"abs\"_norm', 22),\n",
       " ('3__fft_coefficient__coeff_1__attr_\"abs\"', 22),\n",
       " ('flux_diff_2_by_1', 20),\n",
       " ('2__skewness', 20),\n",
       " ('1__kurtosis', 20),\n",
       " ('flux_diff_5_by_4', 20),\n",
       " ('detected_mean', 18),\n",
       " ('flux_norm_fft_2_by_0', 18),\n",
       " ('flux_by_flux_ratio_sq_sum', 18),\n",
       " ('0__fft_coefficient__coeff_0__attr_\"abs\"', 18),\n",
       " ('4__kurtosis', 16),\n",
       " ('3__skewness', 16),\n",
       " ('3__flux_diff', 16),\n",
       " ('1__flux_diff', 14),\n",
       " ('3__flux_by_flux_ratio_sq_sum', 14),\n",
       " ('2__kurtosis', 14),\n",
       " ('3__abs_energy_norm', 14),\n",
       " ('1__fft_coefficient__coeff_0__attr_\"abs\"_norm', 12),\n",
       " ('1__fft_coefficient__coeff_0__attr_\"abs\"', 12),\n",
       " ('bottom__abs_energy_norm', 12),\n",
       " ('flux_skew', 8),\n",
       " ('flux_by_flux_ratio_sq_skew', 8),\n",
       " ('flux_by_flux_ratio_sq__longest_strike_below_mean', 8),\n",
       " ('flux_diff_5_by_3', 8),\n",
       " ('2__fft_coefficient__coeff_0__attr_\"abs\"', 8),\n",
       " ('5__abs_energy_norm', 6),\n",
       " ('3__kurtosis', 6),\n",
       " ('top__abs_energy_norm', 6),\n",
       " ('top__flux_diff', 6),\n",
       " ('flux_err_min', 4),\n",
       " ('flux__cid_ce__normalize_True', 4),\n",
       " ('2__flux_by_flux_ratio_sq_sum', 4),\n",
       " ('outside_2sigma', 4)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
