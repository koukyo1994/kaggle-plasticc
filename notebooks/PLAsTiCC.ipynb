{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTmvWpds4lB5"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "qWYyvfOg5R_d",
    "outputId": "f08af9d9-0ff9-4163-e333-c96f12c0a9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tsfresh in /home/hidehisa/anaconda3/lib/python3.6/site-packages (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.10.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (4.28.1)\n",
      "Requirement already satisfied: requests>=2.9.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (2.18.4)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.4.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.19.1)\n",
      "Requirement already satisfied: pandas>=0.20.3 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (1.14.5)\n",
      "Requirement already satisfied: future>=0.16.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.16.0)\n",
      "Requirement already satisfied: distributed>=1.18.3 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (1.19.1)\n",
      "Requirement already satisfied: statsmodels>=0.8.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (1.11.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.19.1)\n",
      "Requirement already satisfied: dask>=0.15.2 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.15.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from requests>=2.9.1->tsfresh) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from requests>=2.9.1->tsfresh) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from requests>=2.9.1->tsfresh) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from requests>=2.9.1->tsfresh) (2018.4.16)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas>=0.20.3->tsfresh) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas>=0.20.3->tsfresh) (2017.2)\n",
      "Requirement already satisfied: tornado>=4.5.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (4.5.2)\n",
      "Requirement already satisfied: toolz>=0.7.4 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (0.8.2)\n",
      "Requirement already satisfied: msgpack-python in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (0.4.8)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (0.4.0)\n",
      "Requirement already satisfied: click>=6.6 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (6.7)\n",
      "Requirement already satisfied: tblib in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (1.3.2)\n",
      "Requirement already satisfied: psutil in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (5.4.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (0.1.3)\n",
      "Requirement already satisfied: sortedcontainers in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (1.5.7)\n",
      "Requirement already satisfied: heapdict in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from zict>=0.1.3->distributed>=1.18.3->tsfresh) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "AznDz3PNI3Cn",
    "outputId": "c89a95a6-37b9-47e6-834a-e2ab75155ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipdb in /home/hidehisa/anaconda3/lib/python3.6/site-packages (0.11)\n",
      "Requirement already satisfied: ipython>=5.0.0; python_version >= \"3.3\" in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipdb) (6.1.0)\n",
      "Requirement already satisfied: setuptools in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipdb) (36.5.0.post20170921)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.10.2)\n",
      "Requirement already satisfied: decorator in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.1.2)\n",
      "Requirement already satisfied: pickleshare in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.7.4)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.8.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.3.2)\n",
      "Requirement already satisfied: prompt_toolkit<2.0.0,>=1.0.4 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (1.0.15)\n",
      "Requirement already satisfied: pygments in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (2.2.0)\n",
      "Requirement already satisfied: pexpect in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.2.1)\n",
      "Requirement already satisfied: ipython_genutils in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from traitlets>=4.2->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.2.0)\n",
      "Requirement already satisfied: six in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from traitlets>=4.2->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (1.11.0)\n",
      "Requirement already satisfied: wcwidth in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from prompt_toolkit<2.0.0,>=1.0.4->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-hDnjEBJ6BLz",
    "outputId": "40f94c96-3420-4e19-fc6d-c8c9e87546d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/hidehisa/anaconda3/lib/python3.6/site-packages (2.0.12)\n",
      "Requirement already satisfied: scipy in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: scikit-learn in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: numpy in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from lightgbm) (1.14.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "5mWaECEjHlke",
    "outputId": "c795993e-3f6e-4efa-ee35-6b7444107798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in /home/hidehisa/anaconda3/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas) (2017.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tqdm in /home/hidehisa/anaconda3/lib/python3.6/site-packages (4.28.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cK8rb4cy4K5G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "tqdm.pandas(desc=\"apply progress\")\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EUmUBq3m-3dJ",
    "outputId": "1974b0c7-4bbe-4065-dd38-699d4f1ba32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k1ERNuLo_Dm6",
    "outputId": "22950a62-2483-4254-ecdc-c823c41ab6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !cp /content/drive/My\\ Drive/plasticc/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyxxtBk4_4th"
   },
   "outputs": [],
   "source": [
    "# !unzip -q sample_submission.csv.zip\n",
    "# !unzip -q test_set.csv.zip\n",
    "# !unzip -q test_set_metadata.csv.zip\n",
    "# !unzip -q training_set.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVrYEq8aAxEz"
   },
   "source": [
    "## Open training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fidpdfCcA1VY"
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/hidehisa/.kaggle/competitions/plasticc\"\n",
    "train = pd.read_csv(data_dir + \"/train_with_cluster.csv\")\n",
    "meta = pd.read_csv(data_dir + \"/training_set_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8R5UxFwApPH"
   },
   "source": [
    "## Add Cluster to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aYY2gDJwgehY"
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBwKcp2O_YH3"
   },
   "outputs": [],
   "source": [
    "def elbow(d):\n",
    "    data = d.mjd.values.reshape([-1, 1])\n",
    "    kms = [KMeans(n_clusters=i).fit(data) for i in range(2, 6)]\n",
    "    inertias = [km.inertia_ for km in kms]\n",
    "    diff1 = inertias[0] - inertias[1]\n",
    "    diff2 = inertias[1] - inertias[2]\n",
    "    diff3 = inertias[2] - inertias[3]\n",
    "    if diff1 / diff2 > diff2 / diff3:\n",
    "        return kms[1].predict(data)\n",
    "    else:\n",
    "        return kms[2].predict(data)\n",
    "\n",
    "def add_cluster(df):\n",
    "    new_df = (df.groupby(\"object_id\").progress_apply(lambda x: elbow(x))\n",
    "                .to_frame(\"cluster\")\n",
    "                .apply(lambda x: x.apply(pd.Series).stack())\n",
    "                .reset_index()\n",
    "                .drop(\"level_1\", axis=1)\n",
    "             )\n",
    "    new_df = new_df.astype({\"cluster\": int})\n",
    "    df = pd.concat([df, new_df.drop(\"object_id\", axis=1)], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_cluster_multi(d):\n",
    "    n_record = d.shape[0]\n",
    "    default_chunk = n_record // 8\n",
    "    head = 0\n",
    "    df_pool = []\n",
    "    for _ in range(7):\n",
    "        new_df = d.loc[head:head+default_chunk, :]\n",
    "        last_id = new_df.object_id.unique()[-1]\n",
    "        len_last = new_df.query(\"object_id == @last_id\").shape[0]\n",
    "        new_df = new_df.loc[head:head+default_chunk-len_last, :]\n",
    "        df_pool.append(new_df)\n",
    "        head = head + default_chunk - len_last+1\n",
    "    df_pool.append(d.loc[head:, :])\n",
    "    pool = Pool(8)\n",
    "    dfs = pool.map(add_cluster, df_pool)\n",
    "    pool.close()\n",
    "    return pd.concat(dfs)})\n",
    "    df = pd.concat([df, new_df.drop(\"object_id\", axis=1)], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_cluster_multi(d):\n",
    "    n_record = d.shape[0]\n",
    "    default_chunk = n_record // 8\n",
    "    head = 0\n",
    "    df_pool = []\n",
    "    for _ in range(7):\n",
    "        new_df = d.loc[head:head+default_chunk, :]\n",
    "        last_id = new_df.object_id.unique()[-1]\n",
    "        len_last = new_df.query(\"object_id == @last_id\").shape[0]\n",
    "        new_df = new_df.loc[head:head+default_chunk-len_last, :]\n",
    "        df_pool.append(new_df)\n",
    "        head = head + default_chunk - len_last+1\n",
    "    df_pool.append(d.loc[head:, :])\n",
    "    pool = Pool(8)\n",
    "    dfs = pool.map(add_cluster, df_pool)\n",
    "    pool.close()\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "j_U0QDopAM5-",
    "outputId": "5ad0974e-21b7-4170-be65-c3c5930e9c00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply progress: 100%|██████████| 7848/7848 [04:42<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 45s, sys: 1.47 s, total: 4min 46s\n",
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = add_cluster(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVxTBkiqd12A"
   },
   "outputs": [],
   "source": [
    "# train.to_csv(\"train_with_cluster.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5gTAbSt1eCHH",
    "outputId": "f4fa6817-34d8-499c-ae36-9aa4e18eae92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: train_with_cluster.csv (deflated 67%)\n"
     ]
    }
   ],
   "source": [
    "# !zip train_with_cluster.csv.zip train_with_cluster.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYzvaxAoej5O"
   },
   "outputs": [],
   "source": [
    "# !cp train_with_cluster.csv.zip /content/drive/My\\ Drive/plasticc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hMsGaM0bCBX-"
   },
   "source": [
    "## Train Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80dNYR2xB1x1"
   },
   "outputs": [],
   "source": [
    "def basic(d):\n",
    "    df = d.copy()\n",
    "    df[\"flux_ratio_sq\"] = np.power(df[\"flux\"] / df[\"flux_err\"], 2)\n",
    "    df[\"flux_by_flux_ratio_sq\"] = df[\"flux\"] * df[\"flux_ratio_sq\"]\n",
    "\n",
    "    aggs = {\n",
    "        'mjd': ['min', 'max', 'size'],\n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'detected': ['mean'],\n",
    "        'flux_ratio_sq': ['sum', 'skew'],\n",
    "        'flux_by_flux_ratio_sq': ['sum', 'skew'],\n",
    "    }\n",
    "    agg_df = df.groupby('object_id').agg(aggs)\n",
    "    new_columns = [k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "    agg_df.columns = new_columns\n",
    "    agg_df['mjd_diff'] = agg_df['mjd_max'] - agg_df['mjd_min']\n",
    "    agg_df['flux_diff'] = agg_df['flux_max'] - agg_df['flux_min']\n",
    "    agg_df['flux_dif2'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_mean']\n",
    "    agg_df['flux_w_mean'] = agg_df['flux_by_flux_ratio_sq_sum'] / agg_df[\n",
    "        'flux_ratio_sq_sum']\n",
    "    agg_df['flux_dif3'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_w_mean']\n",
    "\n",
    "    del agg_df['mjd_max'], agg_df['mjd_min']\n",
    "\n",
    "    fcp = {\n",
    "        'fft_coefficient': [{\n",
    "            'coeff': 0,\n",
    "            'attr': 'abs'\n",
    "        }, {\n",
    "            'coeff': 1,\n",
    "            'attr': 'abs'\n",
    "        }],\n",
    "        'kurtosis':\n",
    "        None,\n",
    "        'skewness':\n",
    "        None\n",
    "    }\n",
    "    agg_df_ts = extract_features(\n",
    "        df,\n",
    "        column_id='object_id',\n",
    "        column_sort='mjd',\n",
    "        column_kind='passband',\n",
    "        column_value='flux',\n",
    "        default_fc_parameters=fcp,\n",
    "        n_jobs=8)\n",
    "    df_det = df[df['detected'] == 1].copy()\n",
    "\n",
    "    agg_df_mjd = extract_features(\n",
    "        df_det,\n",
    "        column_id='object_id',\n",
    "        column_value='mjd',\n",
    "        default_fc_parameters={\n",
    "            'maximum': None,\n",
    "            'minimum': None\n",
    "        },\n",
    "        n_jobs=8)\n",
    "    agg_df_mjd['mjd_diff_det'] = agg_df_mjd['mjd__maximum'] - agg_df_mjd[\n",
    "        'mjd__minimum']\n",
    "    del agg_df_mjd['mjd__maximum'], agg_df_mjd['mjd__minimum']\n",
    "    agg_df_ts = pd.merge(agg_df_ts, agg_df_mjd, on='id')\n",
    "    # tsfresh returns a dataframe with an index name='id'\n",
    "    agg_df_ts.index.rename('object_id', inplace=True)\n",
    "    agg_df = pd.merge(agg_df, agg_df_ts, on='object_id')\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "def with_cluster(d):\n",
    "    df = d.copy()\n",
    "    df[\"flux_ratio_sq\"] = np.power(df[\"flux\"] / df[\"flux_err\"], 2)\n",
    "    df[\"flux_by_flux_ratio_sq\"] = df[\"flux\"] * df[\"flux_ratio_sq\"]\n",
    "    aggs = {\n",
    "        'mjd': ['min', 'max', 'size'],\n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'detected': ['mean'],\n",
    "        'flux_ratio_sq': ['sum', 'skew'],\n",
    "        'flux_by_flux_ratio_sq': ['sum', 'skew'],\n",
    "    }\n",
    "    agg_df = df.groupby(['object_id', \"cluster\"]).agg(aggs)\n",
    "    new_columns = [k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "    agg_df.columns = new_columns\n",
    "    agg_df['mjd_diff'] = agg_df['mjd_max'] - agg_df['mjd_min']\n",
    "    agg_df['flux_diff'] = agg_df['flux_max'] - agg_df['flux_min']\n",
    "    agg_df['flux_dif2'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_mean']\n",
    "    agg_df['flux_w_mean'] = agg_df['flux_by_flux_ratio_sq_sum'] / agg_df[\n",
    "        'flux_ratio_sq_sum']\n",
    "    agg_df['flux_dif3'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_w_mean']\n",
    "    agg_df.reset_index(inplace=True)\n",
    "    del agg_df['mjd_max'], agg_df['mjd_min']\n",
    "    agg_df.drop(\"cluster\", axis=1, inplace=True)\n",
    "    agg_df = agg_df.groupby(\"object_id\").agg([\"min\", \"max\", \"std\", \"skew\"])\n",
    "    agg_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in agg_df.columns])\n",
    "\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "def cluster_mean_diff(df):\n",
    "    new_df = df.groupby([\"object_id\", \"cluster\"]).agg({\n",
    "        \"flux\": [\"mean\", \"max\", \"min\"]\n",
    "    })\n",
    "    new_df.columns = pd.Index(\n",
    "        [e[0] + \"_\" + e[1] for e in new_df.columns.tolist()])\n",
    "    new_df[\"normalized_mean\"] = new_df[\"flux_mean\"] / (\n",
    "        new_df[\"flux_max\"] - new_df[\"flux_min\"])\n",
    "    new_df.reset_index(inplace=True)\n",
    "    return new_df.groupby(\"object_id\").agg({\"normalized_mean\": \"std\"})\n",
    "\n",
    "\n",
    "def passband_std_difference(df):\n",
    "    std_df = df.groupby([\"object_id\", \"cluster\", \"passband\"]).agg({\n",
    "        \"flux\": \"std\"\n",
    "    }).reset_index().groupby([\"object_id\",\n",
    "                              \"passband\"])[\"flux\"].mean().reset_index()\n",
    "    std_df_max = std_df.groupby(\"object_id\")[\"flux\"].max()\n",
    "    std_df_min = std_df.groupby(\"object_id\")[\"flux\"].min()\n",
    "    return (std_df_max / std_df_min).reset_index()\n",
    "\n",
    "\n",
    "def linear_slope(df):\n",
    "    new_df = df.groupby([\"object_id\", \"cluster\", \"passband\"]).agg({\n",
    "        \"flux\": [\"max\", \"min\"]\n",
    "    })\n",
    "    new_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in new_df.columns])\n",
    "    new_df.reset_index(inplace=True)\n",
    "    new_df[\"flux_range\"] = new_df[\"flux_max\"] - new_df[\"flux_min\"]\n",
    "    new_df = pd.merge(\n",
    "        df, new_df, how=\"left\", on=[\"object_id\", \"cluster\", \"passband\"])\n",
    "    new_df[\"flux_normalized\"] = new_df[\"flux\"] / new_df[\"flux_range\"]\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    def get_coef_(x):\n",
    "        if x.shape[0] <= 1:\n",
    "            return 0\n",
    "        lr.fit(\n",
    "            x.mjd.values.reshape([-1, 1]),\n",
    "            x.flux_normalized.values.reshape([-1, 1]))\n",
    "        return lr.coef_[0][0]\n",
    "\n",
    "    new_df = new_df.groupby(\n",
    "        [\"object_id\", \"cluster\", \"passband\"],\n",
    "        as_index=False)[\"object_id\", \"cluster\", \"passband\", \"mjd\",\n",
    "                        \"flux_normalized\"].progress_apply(\n",
    "                            lambda x: get_coef_(x)).unstack().groupby(\n",
    "                                \"object_id\").mean().reset_index()\n",
    "    new_df.columns = pd.Index(\n",
    "        [new_df.columns.name + str(e) for e in new_df.columns])\n",
    "    new_df.rename(columns={\"passbandobject_id\": \"object_id\"}, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def linear_slope_multi(d):\n",
    "    n_record = d.shape[0]\n",
    "    default_chunk = n_record // 8\n",
    "    head = 0\n",
    "    df_pool = []\n",
    "    for _ in range(7):\n",
    "        new_df = d.loc[head:head+default_chunk, :]\n",
    "        last_id = new_df.object_id.unique()[-1]\n",
    "        len_last = new_df.query(\"object_id == @last_id\").shape[0]\n",
    "        new_df = new_df.loc[head:head+default_chunk-len_last, :]\n",
    "        df_pool.append(new_df)\n",
    "        head = head + default_chunk - len_last+1\n",
    "    df_pool.append(d.loc[head:, :])\n",
    "    pool = Pool(8)\n",
    "    dfs = pool.map(linear_slope, df_pool)\n",
    "    pool.close()\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "\n",
    "def num_outliers(df):\n",
    "    new_df = df.groupby(\"object_id\").agg({\"flux\": [\"mean\", \"std\"]})\n",
    "    new_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in new_df.columns])\n",
    "    new_df[\"upper_sigma\"] = new_df[\"flux_mean\"] + new_df[\"flux_std\"]\n",
    "    new_df[\"upper_2sigma\"] = new_df[\"flux_mean\"] + 2 * new_df[\"flux_std\"]\n",
    "    new_df[\"lower_sigma\"] = new_df[\"flux_mean\"] - new_df[\"flux_std\"]\n",
    "    new_df[\"lower_2sigma\"] = new_df[\"flux_mean\"] - 2 * new_df[\"flux_std\"]\n",
    "    new_df.drop([\"flux_mean\", \"flux_std\"], axis=1, inplace=True)\n",
    "    new_df = pd.merge(df, new_df, how=\"left\", on=\"object_id\")\n",
    "    new_df[\"outside_sigma\"] = (\n",
    "        (new_df[\"flux\"] > new_df[\"upper_sigma\"]) |\n",
    "        (new_df[\"flux\"] < new_df[\"lower_sigma\"])).astype(int)\n",
    "    new_df[\"outside_2sigma\"] = (\n",
    "        (new_df[\"flux\"] > new_df[\"upper_2sigma\"]) |\n",
    "        (new_df[\"flux\"] < new_df[\"lower_2sigma\"])).astype(int)\n",
    "\n",
    "    return_df = new_df.groupby(\"object_id\").agg({\n",
    "        \"outside_sigma\": \"sum\",\n",
    "        \"outside_2sigma\": \"sum\"\n",
    "    })\n",
    "    return_df.reset_index(inplace=True)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8LKMf0xQChG8"
   },
   "outputs": [],
   "source": [
    "def get_full(df, meta):\n",
    "    agg_basic = basic(df)\n",
    "    agg_cluster = with_cluster(df)\n",
    "\n",
    "    cl_mean_diff = cluster_mean_diff(df)\n",
    "    ps_std_diff = passband_std_difference(df)\n",
    "    lin_sl = linear_slope(df)\n",
    "    num_out = num_outliers(df)\n",
    "\n",
    "    full = pd.merge(agg_basic, agg_cluster, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, cl_mean_diff, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, ps_std_diff, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, lin_sl, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, num_out, how=\"left\", on=\"object_id\")\n",
    "\n",
    "    full = pd.merge(full, meta, how=\"left\", on=\"object_id\")\n",
    "    if \"target\" in full.columns:\n",
    "        full.drop(\"target\", axis=1, inplace=True)\n",
    "    return full\n",
    "\n",
    "\n",
    "def train_data(df, meta):\n",
    "    full = get_full(df, meta)\n",
    "    y = meta.target\n",
    "    classes = sorted(y.unique())\n",
    "    class_weight = {c: 1 for c in classes}\n",
    "\n",
    "    for c in [64, 15]:\n",
    "        class_weight[c] = 2\n",
    "    oof_df = full[[\"object_id\"]]\n",
    "    del full['object_id'], full['distmod'], full['hostgal_specz']\n",
    "    del full['ra'], full['decl'], full['gal_l'], full['gal_b'], full['ddf']\n",
    "    return full, y, classes, class_weight, oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply progress: 100%|██████████| 148786/148786 [00:39<00:00, 3735.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>passband0</th>\n",
       "      <th>passband1</th>\n",
       "      <th>passband2</th>\n",
       "      <th>passband3</th>\n",
       "      <th>passband4</th>\n",
       "      <th>passband5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615</td>\n",
       "      <td>-0.001706</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713</td>\n",
       "      <td>-0.002609</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>-0.002616</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>-0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>-0.003559</td>\n",
       "      <td>-0.003062</td>\n",
       "      <td>-0.003432</td>\n",
       "      <td>-0.002205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745</td>\n",
       "      <td>-0.002952</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>-0.002321</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>-0.003098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>-0.003188</td>\n",
       "      <td>-0.002722</td>\n",
       "      <td>-0.001763</td>\n",
       "      <td>-0.001460</td>\n",
       "      <td>-0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1227</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>-0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1598</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1632</td>\n",
       "      <td>-0.001775</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1920</td>\n",
       "      <td>-0.001821</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.001625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1926</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.002122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2072</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>-0.001880</td>\n",
       "      <td>-0.001217</td>\n",
       "      <td>-0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2103</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.002756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>-0.000846</td>\n",
       "      <td>-0.002626</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2330</td>\n",
       "      <td>-0.000710</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.002075</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>-0.001101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2624</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.001229</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.001532</td>\n",
       "      <td>-0.001027</td>\n",
       "      <td>-0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2677</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2922</td>\n",
       "      <td>-0.001281</td>\n",
       "      <td>-0.001610</td>\n",
       "      <td>-0.001410</td>\n",
       "      <td>-0.001015</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3041</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>-0.000945</td>\n",
       "      <td>-0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3285</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.002954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3423</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-0.002709</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>-0.002554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3489</td>\n",
       "      <td>-0.003829</td>\n",
       "      <td>-0.002845</td>\n",
       "      <td>-0.002865</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.003195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3910</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>-0.002031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4088</td>\n",
       "      <td>-0.001774</td>\n",
       "      <td>-0.002072</td>\n",
       "      <td>-0.001940</td>\n",
       "      <td>-0.001952</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4132</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.002825</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>-0.001172</td>\n",
       "      <td>-0.001863</td>\n",
       "      <td>-0.002032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4171</td>\n",
       "      <td>-0.001134</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>-0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4173</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>-0.002607</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>-0.002206</td>\n",
       "      <td>-0.002501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4220</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4389</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>-0.001867</td>\n",
       "      <td>-0.001414</td>\n",
       "      <td>-0.002382</td>\n",
       "      <td>-0.003474</td>\n",
       "      <td>-0.002299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4595</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.003126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4819</td>\n",
       "      <td>-0.003427</td>\n",
       "      <td>-0.001036</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>-0.001197</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>130219752</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>-0.002055</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>-0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>130231675</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.005028</td>\n",
       "      <td>-0.002433</td>\n",
       "      <td>-0.006071</td>\n",
       "      <td>-0.000615</td>\n",
       "      <td>0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>130263372</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821</th>\n",
       "      <td>130312781</td>\n",
       "      <td>0.257733</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.034533</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.001742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>130319749</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>-0.004736</td>\n",
       "      <td>-0.008112</td>\n",
       "      <td>-0.005232</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>-0.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7823</th>\n",
       "      <td>130330088</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>-0.001244</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7824</th>\n",
       "      <td>130359176</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>-0.014316</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825</th>\n",
       "      <td>130375489</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>-0.005691</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>-0.002907</td>\n",
       "      <td>-0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>130386135</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.053632</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.002272</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7827</th>\n",
       "      <td>130402542</td>\n",
       "      <td>-0.353969</td>\n",
       "      <td>-0.009232</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-0.002849</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>-0.016293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>130408188</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>-0.000719</td>\n",
       "      <td>-0.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>130414189</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>130489916</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>-0.004031</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>-0.018532</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>-0.001271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7831</th>\n",
       "      <td>130552230</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>-0.004457</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7832</th>\n",
       "      <td>130595291</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>130617044</td>\n",
       "      <td>-0.003853</td>\n",
       "      <td>-0.002530</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>130622528</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>-0.016254</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.005062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>130639669</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.030968</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.008905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>130659834</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>-0.002177</td>\n",
       "      <td>-0.003296</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>130678775</td>\n",
       "      <td>-0.010706</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.003766</td>\n",
       "      <td>-0.015670</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.005768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>130684460</td>\n",
       "      <td>-0.006009</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>-0.002142</td>\n",
       "      <td>-0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>130695262</td>\n",
       "      <td>-0.002578</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>-0.002039</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>-0.001899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>130698059</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>-0.016841</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>-0.013308</td>\n",
       "      <td>-0.005186</td>\n",
       "      <td>-0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>130716752</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>-0.009262</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>-0.005831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842</th>\n",
       "      <td>130727624</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.003535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7843</th>\n",
       "      <td>130739978</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>-0.003899</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7844</th>\n",
       "      <td>130755807</td>\n",
       "      <td>-0.002748</td>\n",
       "      <td>0.048252</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.008167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7845</th>\n",
       "      <td>130762946</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>-0.006263</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>-0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>130772921</td>\n",
       "      <td>-0.005635</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7847</th>\n",
       "      <td>130779836</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.001605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7848 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      object_id  passband0  passband1  passband2  passband3  passband4  \\\n",
       "0           615  -0.001706   0.003049   0.003407   0.003532   0.003279   \n",
       "1           713  -0.002609  -0.001209  -0.002616  -0.002109  -0.000896   \n",
       "2           730   0.000407  -0.002277  -0.003559  -0.003062  -0.003432   \n",
       "3           745  -0.002952  -0.001314  -0.001628  -0.002321  -0.002109   \n",
       "4          1124   0.001111  -0.003188  -0.002722  -0.001763  -0.001460   \n",
       "5          1227   0.000403   0.001126  -0.000688  -0.000413  -0.000464   \n",
       "6          1598   0.002337   0.001183   0.001019   0.000483   0.001247   \n",
       "7          1632  -0.001775  -0.000421  -0.000044  -0.002245  -0.000540   \n",
       "8          1920  -0.001821   0.001182  -0.000909  -0.000003  -0.000273   \n",
       "9          1926   0.002650  -0.000245  -0.000276  -0.000125   0.001082   \n",
       "10         2072  -0.001201  -0.001513  -0.003098  -0.001880  -0.001217   \n",
       "11         2103  -0.002005   0.001955   0.003909   0.003193   0.002259   \n",
       "12         2300   0.000829   0.001109  -0.000846  -0.002626  -0.002173   \n",
       "13         2330  -0.000710   0.000791  -0.002075  -0.001955  -0.001531   \n",
       "14         2624   0.000938  -0.001229  -0.001263  -0.001532  -0.001027   \n",
       "15         2677   0.000505   0.000740   0.000568   0.000685   0.001160   \n",
       "16         2922  -0.001281  -0.001610  -0.001410  -0.001015  -0.002403   \n",
       "17         3041  -0.000255   0.000616  -0.000500  -0.002792  -0.000945   \n",
       "18         3285   0.005316   0.000943   0.002123   0.002256   0.003871   \n",
       "19         3423  -0.000218  -0.001344  -0.000841  -0.002709  -0.002920   \n",
       "20         3489  -0.003829  -0.002845  -0.002865  -0.001693  -0.001728   \n",
       "21         3910   0.000237   0.000148   0.000054   0.001352  -0.001768   \n",
       "22         4088  -0.001774  -0.002072  -0.001940  -0.001952  -0.001299   \n",
       "23         4132   0.000273  -0.002825  -0.001723  -0.001172  -0.001863   \n",
       "24         4171  -0.001134   0.001577   0.001417   0.001303   0.001719   \n",
       "25         4173  -0.002173  -0.002607  -0.001078  -0.003771  -0.002206   \n",
       "26         4220  -0.000248   0.001016   0.003032   0.002554   0.004397   \n",
       "27         4389   0.001032  -0.001867  -0.001414  -0.002382  -0.003474   \n",
       "28         4595   0.000980   0.001360   0.003354   0.002142   0.001881   \n",
       "29         4819  -0.003427  -0.001036   0.000751  -0.001197   0.000459   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "7818  130219752  -0.002819  -0.004612  -0.001464  -0.002055  -0.001425   \n",
       "7819  130231675  -0.000443  -0.005028  -0.002433  -0.006071  -0.000615   \n",
       "7820  130263372   0.001648   0.000435   0.000230  -0.000698  -0.000135   \n",
       "7821  130312781   0.257733   0.009158   0.002180   0.034533   0.000395   \n",
       "7822  130319749   0.001984  -0.004736  -0.008112  -0.005232  -0.000895   \n",
       "7823  130330088   0.006197   0.003133   0.000840  -0.000695  -0.001244   \n",
       "7824  130359176   0.000056   0.006752   0.006108  -0.014316  -0.000222   \n",
       "7825  130375489   0.003968  -0.005691  -0.000892  -0.000854  -0.002907   \n",
       "7826  130386135   0.002376   0.053632  -0.000210  -0.002272   0.000146   \n",
       "7827  130402542  -0.353969  -0.009232   0.000172  -0.002849  -0.007794   \n",
       "7828  130408188  -0.002358   0.009819   0.001088   0.000814  -0.000719   \n",
       "7829  130414189  -0.001483  -0.000279   0.000391   0.004228   0.000585   \n",
       "7830  130489916  -0.000348  -0.004031  -0.001427  -0.018532   0.000192   \n",
       "7831  130552230   0.001290   0.004246  -0.004457   0.003091   0.000893   \n",
       "7832  130595291  -0.001804   0.010215   0.004807   0.000412   0.000213   \n",
       "7833  130617044  -0.003853  -0.002530  -0.001845  -0.001474  -0.002913   \n",
       "7834  130622528   0.009859  -0.016254   0.002879   0.002591   0.002335   \n",
       "7835  130639669  -0.000808  -0.002642  -0.000049  -0.030968   0.005677   \n",
       "7836  130659834   0.002734   0.000861  -0.002177  -0.003296   0.000258   \n",
       "7837  130678775  -0.010706   0.000031  -0.003766  -0.015670   0.001792   \n",
       "7838  130684460  -0.006009   0.001730   0.003499   0.003213  -0.002142   \n",
       "7839  130695262  -0.002578   0.000789  -0.003228  -0.002039   0.001483   \n",
       "7840  130698059  -0.003925  -0.016841   0.013785  -0.013308  -0.005186   \n",
       "7841  130716752  -0.000297  -0.009262   0.002791   0.001341   0.002308   \n",
       "7842  130727624   0.001002  -0.003702   0.001081   0.003147  -0.000173   \n",
       "7843  130739978  -0.000347  -0.005677  -0.003899   0.001948   0.000194   \n",
       "7844  130755807  -0.002748   0.048252   0.004072   0.003849   0.011343   \n",
       "7845  130762946   0.000363   0.021637   0.002925  -0.006263  -0.000425   \n",
       "7846  130772921  -0.005635   0.006498   0.000182   0.001663  -0.004807   \n",
       "7847  130779836   0.001548   0.005559   0.000834   0.001332  -0.000056   \n",
       "\n",
       "      passband5  \n",
       "0      0.002969  \n",
       "1     -0.001617  \n",
       "2     -0.002205  \n",
       "3     -0.003098  \n",
       "4     -0.002168  \n",
       "5     -0.000057  \n",
       "6      0.001181  \n",
       "7     -0.000890  \n",
       "8      0.001625  \n",
       "9      0.002122  \n",
       "10    -0.000767  \n",
       "11     0.002756  \n",
       "12     0.000003  \n",
       "13    -0.001101  \n",
       "14    -0.001495  \n",
       "15    -0.000216  \n",
       "16    -0.002425  \n",
       "17    -0.000651  \n",
       "18     0.002954  \n",
       "19    -0.002554  \n",
       "20    -0.003195  \n",
       "21    -0.002031  \n",
       "22    -0.001429  \n",
       "23    -0.002032  \n",
       "24    -0.000309  \n",
       "25    -0.002501  \n",
       "26     0.003151  \n",
       "27    -0.002299  \n",
       "28     0.003126  \n",
       "29     0.000208  \n",
       "...         ...  \n",
       "7818  -0.000928  \n",
       "7819   0.000857  \n",
       "7820  -0.000156  \n",
       "7821   0.001742  \n",
       "7822  -0.000374  \n",
       "7823   0.000554  \n",
       "7824   0.000561  \n",
       "7825  -0.000332  \n",
       "7826  -0.001080  \n",
       "7827  -0.016293  \n",
       "7828  -0.001932  \n",
       "7829   0.001066  \n",
       "7830  -0.001271  \n",
       "7831   0.001497  \n",
       "7832  -0.001914  \n",
       "7833   0.001148  \n",
       "7834   0.005062  \n",
       "7835   0.008905  \n",
       "7836   0.000839  \n",
       "7837   0.005768  \n",
       "7838  -0.002967  \n",
       "7839  -0.001899  \n",
       "7840  -0.001226  \n",
       "7841  -0.005831  \n",
       "7842  -0.003535  \n",
       "7843  -0.000451  \n",
       "7844   0.008167  \n",
       "7845  -0.000737  \n",
       "7846  -0.001929  \n",
       "7847   0.001605  \n",
       "\n",
       "[7848 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_slope(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Jeawd1ovCpWG",
    "outputId": "767f62f9-a28a-431e-feaa-8bd4b452376f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:04<00:00, 11.64it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 107.15it/s]\n",
      "apply progress: 100%|██████████| 148786/148786 [00:41<00:00, 3602.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 1.09 s, total: 1min 26s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full, y, classes, class_weight, oof_df = train_data(train, meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsC3-yUuaQS7"
   },
   "outputs": [],
   "source": [
    "train_mean = full.mean(axis=0)\n",
    "full.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vHE2eKPaeur3"
   },
   "outputs": [],
   "source": [
    "# full.to_csv(\"full_train.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9Kcwi_EVe76_",
    "outputId": "6e267498-b599-4635-deeb-b1064c7caf54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: full_train.csv (deflated 55%)\n"
     ]
    }
   ],
   "source": [
    "# !zip full_train.csv.zip full_train.csv\n",
    "# !cp full_train.csv.zip /content/drive/My\\ Drive/plasticc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7V-R3l1IVFK"
   },
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HT3ihC7EHOjE"
   },
   "outputs": [],
   "source": [
    "def multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {\n",
    "        6: 1,\n",
    "        15: 2,\n",
    "        16: 1,\n",
    "        42: 1,\n",
    "        52: 1,\n",
    "        53: 1,\n",
    "        62: 1,\n",
    "        64: 2,\n",
    "        65: 1,\n",
    "        67: 1,\n",
    "        88: 1,\n",
    "        90: 1,\n",
    "        92: 1,\n",
    "        95: 1\n",
    "    }\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array(\n",
    "        [class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = -np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lgb_multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {\n",
    "        6: 1,\n",
    "        15: 2,\n",
    "        16: 1,\n",
    "        42: 1,\n",
    "        52: 1,\n",
    "        53: 1,\n",
    "        62: 1,\n",
    "        64: 2,\n",
    "        65: 1,\n",
    "        67: 1,\n",
    "        88: 1,\n",
    "        90: 1,\n",
    "        92: 1,\n",
    "        95: 1\n",
    "    }\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n",
    "\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array(\n",
    "        [class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = -np.sum(y_w) / np.sum(class_arr)\n",
    "    return 'wloss', loss, False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqLsbJ9UXUlD"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkxlccvqXV4V"
   },
   "outputs": [],
   "source": [
    "def save_importances(importances_):\n",
    "    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n",
    "    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    sns.barplot(\n",
    "        x='gain',\n",
    "        y='feature',\n",
    "        data=importances_.sort_values('mean_gain', ascending=False)[:250])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('importances.png')\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def save_cm(y, oof_preds, path):\n",
    "    unique_y = np.unique(y)\n",
    "    class_map = dict()\n",
    "    for i, val in enumerate(unique_y):\n",
    "        class_map[val] = i\n",
    "\n",
    "    y_map = np.zeros((y.shape[0], ))\n",
    "    y_map = np.array([class_map[val] for val in y])\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_map, np.argmax(oof_preds, axis=-1))\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    sample_sub = pd.read_csv(path)\n",
    "    class_names = list(sample_sub.columns[1:-1])\n",
    "    del sample_sub\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plot_confusion_matrix(\n",
    "        cnf_matrix,\n",
    "        classes=class_names,\n",
    "        normalize=True,\n",
    "        title='Confusion matrix')\n",
    "    plt.savefig(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJ5iBhWKXzCi"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1679
    },
    "colab_type": "code",
    "id": "05fOI0pgXvzy",
    "outputId": "1c09a6c6-1fde-4ca7-8079-0cbb8348f74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.791046\ttraining's wloss: 0.782572\tvalid_1's multi_logloss: 1.1569\tvalid_1's wloss: 0.961849\n",
      "[200]\ttraining's multi_logloss: 0.519309\ttraining's wloss: 0.507654\tvalid_1's multi_logloss: 0.931898\tvalid_1's wloss: 0.781479\n",
      "[300]\ttraining's multi_logloss: 0.395948\ttraining's wloss: 0.383851\tvalid_1's multi_logloss: 0.844591\tvalid_1's wloss: 0.740949\n",
      "[400]\ttraining's multi_logloss: 0.321824\ttraining's wloss: 0.310062\tvalid_1's multi_logloss: 0.797383\tvalid_1's wloss: 0.73397\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's multi_logloss: 0.314616\ttraining's wloss: 0.302846\tvalid_1's multi_logloss: 0.793141\tvalid_1's wloss: 0.733913\n",
      "0.7339133068049176\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.794798\ttraining's wloss: 0.788552\tvalid_1's multi_logloss: 1.14217\tvalid_1's wloss: 0.966386\n",
      "[200]\ttraining's multi_logloss: 0.520398\ttraining's wloss: 0.510283\tvalid_1's multi_logloss: 0.910448\tvalid_1's wloss: 0.779569\n",
      "[300]\ttraining's multi_logloss: 0.398767\ttraining's wloss: 0.387835\tvalid_1's multi_logloss: 0.822566\tvalid_1's wloss: 0.752474\n",
      "Early stopping, best iteration is:\n",
      "[337]\ttraining's multi_logloss: 0.367755\ttraining's wloss: 0.356637\tvalid_1's multi_logloss: 0.801615\tvalid_1's wloss: 0.751614\n",
      "0.7516137144366009\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.785985\ttraining's wloss: 0.778456\tvalid_1's multi_logloss: 1.16\tvalid_1's wloss: 0.942559\n",
      "[200]\ttraining's multi_logloss: 0.515555\ttraining's wloss: 0.504597\tvalid_1's multi_logloss: 0.931098\tvalid_1's wloss: 0.743684\n",
      "[300]\ttraining's multi_logloss: 0.394073\ttraining's wloss: 0.382874\tvalid_1's multi_logloss: 0.843563\tvalid_1's wloss: 0.695798\n",
      "[400]\ttraining's multi_logloss: 0.321287\ttraining's wloss: 0.310477\tvalid_1's multi_logloss: 0.795194\tvalid_1's wloss: 0.683799\n",
      "[500]\ttraining's multi_logloss: 0.269587\ttraining's wloss: 0.25931\tvalid_1's multi_logloss: 0.761341\tvalid_1's wloss: 0.680886\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's multi_logloss: 0.272359\ttraining's wloss: 0.26204\tvalid_1's multi_logloss: 0.762842\tvalid_1's wloss: 0.679958\n",
      "0.6799576871934968\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.794843\ttraining's wloss: 0.785983\tvalid_1's multi_logloss: 1.15358\tvalid_1's wloss: 0.938145\n",
      "[200]\ttraining's multi_logloss: 0.520275\ttraining's wloss: 0.509143\tvalid_1's multi_logloss: 0.918026\tvalid_1's wloss: 0.737301\n",
      "[300]\ttraining's multi_logloss: 0.397429\ttraining's wloss: 0.385636\tvalid_1's multi_logloss: 0.825149\tvalid_1's wloss: 0.686327\n",
      "[400]\ttraining's multi_logloss: 0.321491\ttraining's wloss: 0.31003\tvalid_1's multi_logloss: 0.771236\tvalid_1's wloss: 0.669702\n",
      "Early stopping, best iteration is:\n",
      "[446]\ttraining's multi_logloss: 0.295504\ttraining's wloss: 0.284256\tvalid_1's multi_logloss: 0.753422\tvalid_1's wloss: 0.664843\n",
      "0.6648431898905458\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.791076\ttraining's wloss: 0.782479\tvalid_1's multi_logloss: 1.15887\tvalid_1's wloss: 0.98094\n",
      "[200]\ttraining's multi_logloss: 0.519397\ttraining's wloss: 0.507734\tvalid_1's multi_logloss: 0.920106\tvalid_1's wloss: 0.781038\n",
      "[300]\ttraining's multi_logloss: 0.397541\ttraining's wloss: 0.385769\tvalid_1's multi_logloss: 0.820369\tvalid_1's wloss: 0.722657\n",
      "[400]\ttraining's multi_logloss: 0.324109\ttraining's wloss: 0.312608\tvalid_1's multi_logloss: 0.764708\tvalid_1's wloss: 0.701701\n",
      "Early stopping, best iteration is:\n",
      "[433]\ttraining's multi_logloss: 0.305688\ttraining's wloss: 0.294244\tvalid_1's multi_logloss: 0.752339\tvalid_1's wloss: 0.69989\n",
      "0.6998898587930915\n",
      "MULTI WEIGHTED LOG LOSS : 0.70598 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 14,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': .9,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'reg_alpha': .01,\n",
    "    'reg_lambda': .01,\n",
    "    'min_split_gain': 0.01,\n",
    "    'min_child_weight': 10,\n",
    "    'n_estimators': 1000,\n",
    "    'silent': -1,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 3\n",
    "}\n",
    "\n",
    "# Compute weights\n",
    "w = y.value_counts()\n",
    "weights = {i: np.sum(w) / w[i] for i in w.index}\n",
    "oof_preds = np.zeros((len(full), np.unique(y).shape[0]))\n",
    "\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    trn_x, trn_y = full.iloc[trn_], y.iloc[trn_]\n",
    "    val_x, val_y = full.iloc[val_], y.iloc[val_]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(\n",
    "        trn_x,\n",
    "        trn_y,\n",
    "        eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "        eval_metric=lgb_multi_weighted_logloss,\n",
    "        verbose=100,\n",
    "        early_stopping_rounds=50,\n",
    "        sample_weight=trn_y.map(weights))\n",
    "    oof_preds[val_, :] = clf.predict_proba(\n",
    "        val_x, num_iteration=clf.best_iteration_)\n",
    "    print(multi_weighted_logloss(val_y, oof_preds[val_, :]))\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = full.columns\n",
    "    imp_df['gain'] = clf.feature_importances_\n",
    "    imp_df['fold'] = fold_ + 1\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "    clfs.append(clf)\n",
    "\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(\n",
    "    y_true=y, y_preds=oof_preds))\n",
    "save_importances(importances_=importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "UN8UkPi8YBcB",
    "outputId": "c3d939cf-bbb1-4b56-bd35-b59b96ce35e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    }
   ],
   "source": [
    "save_importances(importances_=importances)\n",
    "save_cm(y, oof_preds, data_dir + \"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mjd_size</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>flux_skew</th>\n",
       "      <th>flux_err_min</th>\n",
       "      <th>flux_err_max</th>\n",
       "      <th>flux_err_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>passband1</th>\n",
       "      <th>passband2</th>\n",
       "      <th>passband3</th>\n",
       "      <th>passband4</th>\n",
       "      <th>passband5</th>\n",
       "      <th>outside_sigma</th>\n",
       "      <th>outside_2sigma</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>mwebv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352</td>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-123.096998</td>\n",
       "      <td>-89.477524</td>\n",
       "      <td>394.109851</td>\n",
       "      <td>-0.349540</td>\n",
       "      <td>2.130510</td>\n",
       "      <td>12.845472</td>\n",
       "      <td>4.482743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>115</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350</td>\n",
       "      <td>-14.735178</td>\n",
       "      <td>14.770886</td>\n",
       "      <td>-1.423351</td>\n",
       "      <td>-0.873033</td>\n",
       "      <td>6.471144</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.639458</td>\n",
       "      <td>9.115748</td>\n",
       "      <td>2.359620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>-0.002616</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330</td>\n",
       "      <td>-19.159811</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>2.267434</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>8.022239</td>\n",
       "      <td>3.177854</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>11.281384</td>\n",
       "      <td>2.471061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>-0.003559</td>\n",
       "      <td>-0.003062</td>\n",
       "      <td>-0.003432</td>\n",
       "      <td>-0.002205</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>351</td>\n",
       "      <td>-15.494463</td>\n",
       "      <td>220.795212</td>\n",
       "      <td>8.909206</td>\n",
       "      <td>1.035895</td>\n",
       "      <td>27.558208</td>\n",
       "      <td>4.979826</td>\n",
       "      <td>0.567170</td>\n",
       "      <td>55.892746</td>\n",
       "      <td>2.555576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>-0.002321</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352</td>\n",
       "      <td>-16.543753</td>\n",
       "      <td>143.600189</td>\n",
       "      <td>7.145702</td>\n",
       "      <td>1.141288</td>\n",
       "      <td>20.051722</td>\n",
       "      <td>4.406298</td>\n",
       "      <td>0.695277</td>\n",
       "      <td>11.383690</td>\n",
       "      <td>2.753004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003188</td>\n",
       "      <td>-0.002722</td>\n",
       "      <td>-0.001763</td>\n",
       "      <td>-0.001460</td>\n",
       "      <td>-0.002168</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mjd_size     flux_min    flux_max   flux_mean  flux_median    flux_std  \\\n",
       "0       352 -1100.440063  660.626343 -123.096998   -89.477524  394.109851   \n",
       "1       350   -14.735178   14.770886   -1.423351    -0.873033    6.471144   \n",
       "2       330   -19.159811   47.310059    2.267434     0.409172    8.022239   \n",
       "3       351   -15.494463  220.795212    8.909206     1.035895   27.558208   \n",
       "4       352   -16.543753  143.600189    7.145702     1.141288   20.051722   \n",
       "\n",
       "   flux_skew  flux_err_min  flux_err_max  flux_err_mean  ...    passband1  \\\n",
       "0  -0.349540      2.130510     12.845472       4.482743  ...     0.003049   \n",
       "1   0.014989      0.639458      9.115748       2.359620  ...    -0.001209   \n",
       "2   3.177854      0.695106     11.281384       2.471061  ...    -0.002277   \n",
       "3   4.979826      0.567170     55.892746       2.555576  ...    -0.001314   \n",
       "4   4.406298      0.695277     11.383690       2.753004  ...    -0.003188   \n",
       "\n",
       "   passband2  passband3  passband4  passband5  outside_sigma  outside_2sigma  \\\n",
       "0   0.003407   0.003532   0.003279   0.002969            115              17   \n",
       "1  -0.002616  -0.002109  -0.000896  -0.001617            136               4   \n",
       "2  -0.003559  -0.003062  -0.003432  -0.002205             31              18   \n",
       "3  -0.001628  -0.002321  -0.002109  -0.003098             21              15   \n",
       "4  -0.002722  -0.001763  -0.001460  -0.002168             27              12   \n",
       "\n",
       "   hostgal_photoz  hostgal_photoz_err  mwebv  \n",
       "0          0.0000              0.0000  0.017  \n",
       "1          1.6267              0.2552  0.007  \n",
       "2          0.2262              0.0157  0.021  \n",
       "3          0.2813              1.1523  0.007  \n",
       "4          0.2415              0.0176  0.024  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUSDtkDkZa-S"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0OLVvaQY0si"
   },
   "outputs": [],
   "source": [
    "def predict_chunk(df_, clfs_, meta_, features, train_mean):\n",
    "    # Group by object id\n",
    "    df_ = add_cluster(df_)\n",
    "    if i_c == 0:\n",
    "        df_.to_csv('test_with_cluster.csv', header=True, mode='a', index=False)\n",
    "    else:\n",
    "        df_.to_csv('test_with_cluster.csv', header=False, mode='a', index=False)\n",
    "    agg_ = get_full(df_, meta_)\n",
    "\n",
    "    full_test = agg_.fillna(0)\n",
    "    \n",
    "    if i_c == 0:\n",
    "        full_test.to_csv('full_test.csv', header=True, mode='a', index=False)\n",
    "    else:\n",
    "        full_test.to_csv('full_test.csv', header=False, mode='a', index=False)\n",
    "    # Make predictions\n",
    "    preds_ = None\n",
    "    for clf in clfs_:\n",
    "        if preds_ is None:\n",
    "            preds_ = clf.predict_proba(full_test[features]) / len(clfs_)\n",
    "        else:\n",
    "            preds_ += clf.predict_proba(full_test[features]) / len(clfs_)\n",
    "\n",
    "    # Compute preds_99 as the proba of class not being any of the others\n",
    "    # preds_99 = 0.1 gives 1.769\n",
    "    preds_99 = np.ones(preds_.shape[0])\n",
    "    for i in range(preds_.shape[1]):\n",
    "        preds_99 *= (1 - preds_[:, i])\n",
    "\n",
    "    # Create DataFrame from predictions\n",
    "    preds_df_ = pd.DataFrame(preds_, columns=['class_' + str(s) for s in clfs_[0].classes_])\n",
    "    preds_df_['object_id'] = full_test['object_id']\n",
    "    preds_df_['class_99'] = 0.14 * preds_99 / np.mean(preds_99) \n",
    "    return preds_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "meta_test = pd.read_csv(data_dir + '/test_set_metadata.csv')\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "test = pd.read_csv(data_dir + \"/test_set.csv\", nrows=50000000)\n",
    "last_id = test.object_id.unique()[-1]\n",
    "len_last = test.query(\"object_id == @last_id\").shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116295367"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.loc[:50000000-len_last-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>mjd</th>\n",
       "      <th>passband</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_err</th>\n",
       "      <th>detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49999891</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60531.1871</td>\n",
       "      <td>2</td>\n",
       "      <td>2.345377</td>\n",
       "      <td>3.148552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999892</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60534.1399</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.607878</td>\n",
       "      <td>4.702101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999893</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60536.1004</td>\n",
       "      <td>5</td>\n",
       "      <td>1.196585</td>\n",
       "      <td>24.526249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999894</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60537.2421</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.133058</td>\n",
       "      <td>4.880866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999895</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60545.1649</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.941238</td>\n",
       "      <td>4.122555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999896</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60550.1260</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.571225</td>\n",
       "      <td>3.191211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999897</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60557.0569</td>\n",
       "      <td>0</td>\n",
       "      <td>5.051228</td>\n",
       "      <td>8.116439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999898</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60566.0340</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.292259</td>\n",
       "      <td>21.673841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999899</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60572.2355</td>\n",
       "      <td>4</td>\n",
       "      <td>-27.634487</td>\n",
       "      <td>16.113247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999900</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60573.0327</td>\n",
       "      <td>4</td>\n",
       "      <td>7.762663</td>\n",
       "      <td>9.448179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999901</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60576.9915</td>\n",
       "      <td>5</td>\n",
       "      <td>34.234898</td>\n",
       "      <td>46.895260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999902</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60579.0142</td>\n",
       "      <td>3</td>\n",
       "      <td>-7.086708</td>\n",
       "      <td>7.817007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999903</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60581.0571</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.182376</td>\n",
       "      <td>3.361635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999904</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60584.9927</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.652431</td>\n",
       "      <td>9.778281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999905</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60591.9977</td>\n",
       "      <td>5</td>\n",
       "      <td>3.535146</td>\n",
       "      <td>13.844622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999906</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60599.0593</td>\n",
       "      <td>5</td>\n",
       "      <td>-7.696403</td>\n",
       "      <td>22.855150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999907</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60601.0354</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>5.880628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999908</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60615.0181</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.762956</td>\n",
       "      <td>9.096793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999909</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60627.0418</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.534744</td>\n",
       "      <td>32.996201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999910</th>\n",
       "      <td>116295365</td>\n",
       "      <td>60633.0322</td>\n",
       "      <td>4</td>\n",
       "      <td>2.254674</td>\n",
       "      <td>12.672300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          object_id         mjd  passband       flux   flux_err  detected\n",
       "49999891  116295365  60531.1871         2   2.345377   3.148552         0\n",
       "49999892  116295365  60534.1399         3  -6.607878   4.702101         0\n",
       "49999893  116295365  60536.1004         5   1.196585  24.526249         0\n",
       "49999894  116295365  60537.2421         3  -5.133058   4.880866         0\n",
       "49999895  116295365  60545.1649         3  -1.941238   4.122555         0\n",
       "49999896  116295365  60550.1260         2  -2.571225   3.191211         0\n",
       "49999897  116295365  60557.0569         0   5.051228   8.116439         0\n",
       "49999898  116295365  60566.0340         5  -9.292259  21.673841         0\n",
       "49999899  116295365  60572.2355         4 -27.634487  16.113247         0\n",
       "49999900  116295365  60573.0327         4   7.762663   9.448179         0\n",
       "49999901  116295365  60576.9915         5  34.234898  46.895260         0\n",
       "49999902  116295365  60579.0142         3  -7.086708   7.817007         0\n",
       "49999903  116295365  60581.0571         2  -0.182376   3.361635         0\n",
       "49999904  116295365  60584.9927         4  -5.652431   9.778281         0\n",
       "49999905  116295365  60591.9977         5   3.535146  13.844622         0\n",
       "49999906  116295365  60599.0593         5  -7.696403  22.855150         0\n",
       "49999907  116295365  60601.0354         4  -0.143090   5.880628         0\n",
       "49999908  116295365  60615.0181         4  -1.762956   9.096793         0\n",
       "49999909  116295365  60627.0418         5  -1.534744  32.996201         0\n",
       "49999910  116295365  60633.0322         4   2.254674  12.672300         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply progress: 100%|██████████| 338747/338747 [3:27:50<00:00, 27.16it/s]\n"
     ]
    }
   ],
   "source": [
    "test = add_cluster(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"test_with_cluster_0_49999910.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "agg_ = get_full(test, meta_test)\n",
    "full_test = agg_.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: test_with_cluster_0_49999910.csv (deflated 67%)\n"
     ]
    }
   ],
   "source": [
    "!zip test_with_cluster_0_49999910.csv.zip test_with_cluster_0_49999910.csv\n",
    "!cp test_with_cluster_0_49999910.csv.zip /home/hidehisa/.kaggle/competitions/plasticc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1162
    },
    "colab_type": "code",
    "id": "g7i-xAr5Zrn_",
    "outputId": "dd88a71b-5b07-4949-c45f-b637860566cd"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "meta_test = pd.read_csv(data_dir + '/test_set_metadata.csv')\n",
    "# meta_test.set_index('object_id',inplace=True)\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "chunks = 10000000\n",
    "remain_df = None\n",
    "\n",
    "for i_c, df in enumerate(pd.read_csv(data_dir + '/test_set.csv', chunksize=chunks, iterator=True)):\n",
    "    # Check object_ids\n",
    "    # I believe np.unique keeps the order of group_ids as they appear in the file\n",
    "    unique_ids = np.unique(df['object_id'])\n",
    "    new_remain_df = df.loc[df['object_id'] == unique_ids[-1]].copy()\n",
    "    if remain_df is None:\n",
    "        df = df.loc[df['object_id'].isin(unique_ids[:-1])]\n",
    "    else:\n",
    "        df = pd.concat([remain_df, df.loc[df['object_id'].isin(unique_ids[:-1])]], axis=0)\n",
    "    # Create remaining samples df\n",
    "    remain_df = new_remain_df\n",
    "    preds_df = predict_chunk(df_=df,\n",
    "                             clfs_=clfs,\n",
    "                             meta_=meta_test,\n",
    "                             features=full.columns,\n",
    "                             train_mean=train_mean)\n",
    "\n",
    "    if i_c == 0:\n",
    "        preds_df.to_csv('predictions.csv', header=True, mode='a', index=False)\n",
    "    else:\n",
    "        preds_df.to_csv('predictions.csv', header=False, mode='a', index=False)\n",
    "\n",
    "    del preds_df\n",
    "    gc.collect()\n",
    "    \n",
    "    print('%15d done in %5.1f minutes' % (chunks * (i_c + 1), (time.time() - start) / 60), flush=True)\n",
    "\n",
    "# Compute last object in remain_df\n",
    "preds_df = predict_chunk(df_=remain_df,\n",
    "                         clfs_=clfs,\n",
    "                         meta_=meta_test,\n",
    "                         features=full_train.columns,\n",
    "                         train_mean=train_mean)\n",
    "\n",
    "preds_df.to_csv('predictions.csv', header=False, mode='a', index=False)\n",
    "#!zip test_with_cluster.csv.zip test_with_cluster.csv\n",
    "#!zip full_test.csv.zip full_test.csv\n",
    "#!cp test_with_cluster.csv.zip /content/drive/My\\ Drive/plasticc/\n",
    "#!cp full_test.csv.zip /content/drive/My\\ Drive/plasticc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PLAsTiCC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
