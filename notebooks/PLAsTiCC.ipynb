{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTmvWpds4lB5"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "qWYyvfOg5R_d",
    "outputId": "f08af9d9-0ff9-4163-e333-c96f12c0a9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tsfresh\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/32/265c651f4fd70751f5ada348af0f9e322b058eddcda6a6f9bb305c8d270a/tsfresh-0.11.1-py2.py3-none-any.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 646kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (1.14.5)\n",
      "Requirement already satisfied: pandas>=0.20.3 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.23.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (1.11.0)\n",
      "Requirement already satisfied: distributed>=1.18.3 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (1.19.1)\n",
      "Requirement already satisfied: dask>=0.15.2 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.15.3)\n",
      "Requirement already satisfied: statsmodels>=0.8.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.8.0)\n",
      "Requirement already satisfied: requests>=2.9.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (2.18.4)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.4.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.19.1)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.10.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (4.19.5)\n",
      "Requirement already satisfied: future>=0.16.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from tsfresh) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas>=0.20.3->tsfresh) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas>=0.20.3->tsfresh) (2017.2)\n",
      "Requirement already satisfied: tornado>=4.5.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (4.5.2)\n",
      "Requirement already satisfied: toolz>=0.7.4 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (0.8.2)\n",
      "Requirement already satisfied: msgpack-python in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (0.4.8)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (0.4.0)\n",
      "Requirement already satisfied: click>=6.6 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (6.7)\n",
      "Requirement already satisfied: tblib in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (1.3.2)\n",
      "Requirement already satisfied: psutil in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (5.4.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (0.1.3)\n",
      "Requirement already satisfied: sortedcontainers in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from distributed>=1.18.3->tsfresh) (1.5.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from requests>=2.9.1->tsfresh) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from requests>=2.9.1->tsfresh) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from requests>=2.9.1->tsfresh) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from requests>=2.9.1->tsfresh) (2018.4.16)\n",
      "Requirement already satisfied: heapdict in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from zict>=0.1.3->distributed>=1.18.3->tsfresh) (1.0.0)\n",
      "Installing collected packages: tsfresh\n",
      "Successfully installed tsfresh-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "AznDz3PNI3Cn",
    "outputId": "c89a95a6-37b9-47e6-834a-e2ab75155ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipdb in /home/hidehisa/anaconda3/lib/python3.6/site-packages (0.11)\n",
      "Requirement already satisfied: setuptools in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipdb) (36.5.0.post20170921)\n",
      "Requirement already satisfied: ipython>=5.0.0; python_version >= \"3.3\" in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipdb) (6.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.10.2)\n",
      "Requirement already satisfied: decorator in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.1.2)\n",
      "Requirement already satisfied: pickleshare in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.7.4)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.8.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.3.2)\n",
      "Requirement already satisfied: prompt_toolkit<2.0.0,>=1.0.4 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (1.0.15)\n",
      "Requirement already satisfied: pygments in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (2.2.0)\n",
      "Requirement already satisfied: pexpect in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.2.1)\n",
      "Requirement already satisfied: ipython_genutils in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from traitlets>=4.2->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.2.0)\n",
      "Requirement already satisfied: six in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from traitlets>=4.2->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (1.11.0)\n",
      "Requirement already satisfied: wcwidth in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from prompt_toolkit<2.0.0,>=1.0.4->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-hDnjEBJ6BLz",
    "outputId": "40f94c96-3420-4e19-fc6d-c8c9e87546d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/hidehisa/anaconda3/lib/python3.6/site-packages (2.0.12)\n",
      "Requirement already satisfied: numpy in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from lightgbm) (1.14.5)\n",
      "Requirement already satisfied: scikit-learn in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: scipy in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from lightgbm) (0.19.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "5mWaECEjHlke",
    "outputId": "c795993e-3f6e-4efa-ee35-6b7444107798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in /home/hidehisa/anaconda3/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from pandas) (2017.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/hidehisa/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cK8rb4cy4K5G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hidehisa/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EUmUBq3m-3dJ",
    "outputId": "1974b0c7-4bbe-4065-dd38-699d4f1ba32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k1ERNuLo_Dm6",
    "outputId": "22950a62-2483-4254-ecdc-c823c41ab6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !cp /content/drive/My\\ Drive/plasticc/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyxxtBk4_4th"
   },
   "outputs": [],
   "source": [
    "# !unzip -q sample_submission.csv.zip\n",
    "# !unzip -q test_set.csv.zip\n",
    "# !unzip -q test_set_metadata.csv.zip\n",
    "# !unzip -q training_set.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVrYEq8aAxEz"
   },
   "source": [
    "## Open training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fidpdfCcA1VY"
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/hidehisa/.kaggle/competitions/plasticc\"\n",
    "train = pd.read_csv(data_dir + \"/training_set.csv\")\n",
    "meta = pd.read_csv(data_dir + \"/training_set_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8R5UxFwApPH"
   },
   "source": [
    "## Add Cluster to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aYY2gDJwgehY"
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBwKcp2O_YH3"
   },
   "outputs": [],
   "source": [
    "def elbow(d):\n",
    "    data = d.mjd.values.reshape([-1, 1])\n",
    "    kms = [KMeans(n_clusters=i).fit(data) for i in range(2, 6)]\n",
    "    inertias = [km.inertia_ for km in kms]\n",
    "    diff1 = inertias[0] - inertias[1]\n",
    "    diff2 = inertias[1] - inertias[2]\n",
    "    diff3 = inertias[2] - inertias[3]\n",
    "    if diff1 / diff2 > diff2 / diff3:\n",
    "        return kms[1].predict(data)\n",
    "    else:\n",
    "        return kms[2].predict(data)\n",
    "\n",
    "def add_cluster(df):\n",
    "    new_df = (df.groupby(\"object_id\").apply(lambda x: elbow(x))\n",
    "                .to_frame(\"cluster\")\n",
    "                .apply(lambda x: x.apply(pd.Series).stack())\n",
    "                .reset_index()\n",
    "                .drop(\"level_1\", axis=1)\n",
    "             )\n",
    "    new_df = new_df.astype({\"cluster\": int})\n",
    "    df = pd.concat([df, new_df.drop(\"object_id\", axis=1)], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_cluster_multi(d):\n",
    "    n_record = d.shape[0]\n",
    "    default_chunk = n_record // 8\n",
    "    head = 0\n",
    "    df_pool = []\n",
    "    for _ in range(7):\n",
    "        new_df = d.loc[head:head+default_chunk, :]\n",
    "        last_id = new_df.object_id.unique()[-1]\n",
    "        len_last = new_df.query(\"object_id == @last_id\").shape[0]\n",
    "        new_df = new_df.loc[head:head+default_chunk-len_last, :]\n",
    "        df_pool.append(new_df)\n",
    "        head = head + default_chunk - len_last+1\n",
    "    df_pool.append(d.loc[head:, :])\n",
    "    pool = Pool(8)\n",
    "    dfs = pool.map(add_cluster, df_pool)\n",
    "    pool.close()\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "j_U0QDopAM5-",
    "outputId": "5ad0974e-21b7-4170-be65-c3c5930e9c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 28s, sys: 0 ns, total: 4min 28s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = add_cluster(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "JR11vLJAdy0x",
    "outputId": "bc15cd44-92c4-4851-b369-feb44826aa3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.query(\"object_id == 615\").cluster.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVxTBkiqd12A"
   },
   "outputs": [],
   "source": [
    "# train.to_csv(\"train_with_cluster.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5gTAbSt1eCHH",
    "outputId": "f4fa6817-34d8-499c-ae36-9aa4e18eae92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: train_with_cluster.csv (deflated 67%)\n"
     ]
    }
   ],
   "source": [
    "# !zip train_with_cluster.csv.zip train_with_cluster.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYzvaxAoej5O"
   },
   "outputs": [],
   "source": [
    "# !cp train_with_cluster.csv.zip /content/drive/My\\ Drive/plasticc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hMsGaM0bCBX-"
   },
   "source": [
    "## Train Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80dNYR2xB1x1"
   },
   "outputs": [],
   "source": [
    "def basic(d):\n",
    "    df = d.copy()\n",
    "    df[\"flux_ratio_sq\"] = np.power(df[\"flux\"] / df[\"flux_err\"], 2)\n",
    "    df[\"flux_by_flux_ratio_sq\"] = df[\"flux\"] * df[\"flux_ratio_sq\"]\n",
    "\n",
    "    aggs = {\n",
    "        'mjd': ['min', 'max', 'size'],\n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'detected': ['mean'],\n",
    "        'flux_ratio_sq': ['sum', 'skew'],\n",
    "        'flux_by_flux_ratio_sq': ['sum', 'skew'],\n",
    "    }\n",
    "    agg_df = df.groupby('object_id').agg(aggs)\n",
    "    new_columns = [k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "    agg_df.columns = new_columns\n",
    "    agg_df['mjd_diff'] = agg_df['mjd_max'] - agg_df['mjd_min']\n",
    "    agg_df['flux_diff'] = agg_df['flux_max'] - agg_df['flux_min']\n",
    "    agg_df['flux_dif2'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_mean']\n",
    "    agg_df['flux_w_mean'] = agg_df['flux_by_flux_ratio_sq_sum'] / agg_df[\n",
    "        'flux_ratio_sq_sum']\n",
    "    agg_df['flux_dif3'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_w_mean']\n",
    "\n",
    "    del agg_df['mjd_max'], agg_df['mjd_min']\n",
    "\n",
    "    fcp = {\n",
    "        'fft_coefficient': [{\n",
    "            'coeff': 0,\n",
    "            'attr': 'abs'\n",
    "        }, {\n",
    "            'coeff': 1,\n",
    "            'attr': 'abs'\n",
    "        }],\n",
    "        'kurtosis':\n",
    "        None,\n",
    "        'skewness':\n",
    "        None\n",
    "    }\n",
    "    agg_df_ts = extract_features(\n",
    "        df,\n",
    "        column_id='object_id',\n",
    "        column_sort='mjd',\n",
    "        column_kind='passband',\n",
    "        column_value='flux',\n",
    "        default_fc_parameters=fcp,\n",
    "        n_jobs=8)\n",
    "    df_det = df[df['detected'] == 1].copy()\n",
    "\n",
    "    agg_df_mjd = extract_features(\n",
    "        df_det,\n",
    "        column_id='object_id',\n",
    "        column_value='mjd',\n",
    "        default_fc_parameters={\n",
    "            'maximum': None,\n",
    "            'minimum': None\n",
    "        },\n",
    "        n_jobs=8)\n",
    "    agg_df_mjd['mjd_diff_det'] = agg_df_mjd['mjd__maximum'] - agg_df_mjd[\n",
    "        'mjd__minimum']\n",
    "    del agg_df_mjd['mjd__maximum'], agg_df_mjd['mjd__minimum']\n",
    "    agg_df_ts = pd.merge(agg_df_ts, agg_df_mjd, on='id')\n",
    "    # tsfresh returns a dataframe with an index name='id'\n",
    "    agg_df_ts.index.rename('object_id', inplace=True)\n",
    "    agg_df = pd.merge(agg_df, agg_df_ts, on='object_id')\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "def with_cluster(d):\n",
    "    df = d.copy()\n",
    "    df[\"flux_ratio_sq\"] = np.power(df[\"flux\"] / df[\"flux_err\"], 2)\n",
    "    df[\"flux_by_flux_ratio_sq\"] = df[\"flux\"] * df[\"flux_ratio_sq\"]\n",
    "    aggs = {\n",
    "        'mjd': ['min', 'max', 'size'],\n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'detected': ['mean'],\n",
    "        'flux_ratio_sq': ['sum', 'skew'],\n",
    "        'flux_by_flux_ratio_sq': ['sum', 'skew'],\n",
    "    }\n",
    "    agg_df = df.groupby(['object_id', \"cluster\"]).agg(aggs)\n",
    "    new_columns = [k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "    agg_df.columns = new_columns\n",
    "    agg_df['mjd_diff'] = agg_df['mjd_max'] - agg_df['mjd_min']\n",
    "    agg_df['flux_diff'] = agg_df['flux_max'] - agg_df['flux_min']\n",
    "    agg_df['flux_dif2'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_mean']\n",
    "    agg_df['flux_w_mean'] = agg_df['flux_by_flux_ratio_sq_sum'] / agg_df[\n",
    "        'flux_ratio_sq_sum']\n",
    "    agg_df['flux_dif3'] = (\n",
    "        agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_w_mean']\n",
    "    agg_df.reset_index(inplace=True)\n",
    "    del agg_df['mjd_max'], agg_df['mjd_min']\n",
    "    agg_df.drop(\"cluster\", axis=1, inplace=True)\n",
    "    agg_df = agg_df.groupby(\"object_id\").agg([\"min\", \"max\", \"std\", \"skew\"])\n",
    "    agg_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in agg_df.columns])\n",
    "\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "def cluster_mean_diff(df):\n",
    "    new_df = df.groupby([\"object_id\", \"cluster\"]).agg({\n",
    "        \"flux\": [\"mean\", \"max\", \"min\"]\n",
    "    })\n",
    "    new_df.columns = pd.Index(\n",
    "        [e[0] + \"_\" + e[1] for e in new_df.columns.tolist()])\n",
    "    new_df[\"normalized_mean\"] = new_df[\"flux_mean\"] / (\n",
    "        new_df[\"flux_max\"] - new_df[\"flux_min\"])\n",
    "    new_df.reset_index(inplace=True)\n",
    "    return new_df.groupby(\"object_id\").agg({\"normalized_mean\": \"std\"})\n",
    "\n",
    "\n",
    "def passband_std_difference(df):\n",
    "    std_df = df.groupby([\"object_id\", \"cluster\", \"passband\"]).agg({\n",
    "        \"flux\": \"std\"\n",
    "    }).reset_index().groupby([\"object_id\",\n",
    "                              \"passband\"])[\"flux\"].mean().reset_index()\n",
    "    std_df_max = std_df.groupby(\"object_id\")[\"flux\"].max()\n",
    "    std_df_min = std_df.groupby(\"object_id\")[\"flux\"].min()\n",
    "    return (std_df_max / std_df_min).reset_index()\n",
    "\n",
    "\n",
    "def linear_slope(df):\n",
    "    new_df = df.groupby([\"object_id\", \"cluster\", \"passband\"]).agg({\n",
    "        \"flux\": [\"max\", \"min\"]\n",
    "    })\n",
    "    new_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in new_df.columns])\n",
    "    new_df.reset_index(inplace=True)\n",
    "    new_df[\"flux_range\"] = new_df[\"flux_max\"] - new_df[\"flux_min\"]\n",
    "    new_df = pd.merge(\n",
    "        df, new_df, how=\"left\", on=[\"object_id\", \"cluster\", \"passband\"])\n",
    "    new_df[\"flux_normalized\"] = new_df[\"flux\"] / new_df[\"flux_range\"]\n",
    "    lr = LinearRegression()\n",
    "    template = pd.DataFrame({\n",
    "        \"object_id\": new_df.object_id.unique(),\n",
    "        \"passband0\": 0,\n",
    "        \"passband1\": 0,\n",
    "        \"passband2\": 0,\n",
    "        \"passband3\": 0,\n",
    "        \"passband4\": 0,\n",
    "        \"passband5\": 0\n",
    "    })\n",
    "    for objid in new_df.object_id.unique():\n",
    "        obj_df = new_df.query(\"object_id == @objid\")[[\n",
    "            \"mjd\", \"cluster\", \"passband\", \"flux_normalized\"\n",
    "        ]]\n",
    "        passbands = [[] for _ in range(6)]\n",
    "        for cl in obj_df.cluster.unique():\n",
    "            cluster_df = obj_df.query(\"cluster == @cl\")\n",
    "            for ps in cluster_df.passband.unique():\n",
    "                ps_df = cluster_df.query(\"passband == @ps\")\n",
    "                if ps_df.shape[0] <= 1:\n",
    "                    passbands[ps].append(0)\n",
    "                    continue\n",
    "                lr.fit(ps_df[\"mjd\"].values.reshape([-1, 1]),\n",
    "                       ps_df[\"flux_normalized\"].values.reshape([-1, 1]))\n",
    "                passbands[ps].append(np.abs(lr.coef_)[0][0])\n",
    "        passbands = [np.mean(p) for p in passbands]\n",
    "        for i, ps in enumerate(passbands):\n",
    "            template.loc[template.query(\"object_id == @objid\").\n",
    "                         index, f\"passband{i}\"] = ps\n",
    "    return template\n",
    "\n",
    "\n",
    "def linear_slope_multi(d):\n",
    "    n_record = d.shape[0]\n",
    "    default_chunk = n_record // 8\n",
    "    head = 0\n",
    "    df_pool = []\n",
    "    for _ in range(7):\n",
    "        new_df = d.loc[head:head+default_chunk, :]\n",
    "        last_id = new_df.object_id.unique()[-1]\n",
    "        len_last = new_df.query(\"object_id == @last_id\").shape[0]\n",
    "        new_df = new_df.loc[head:head+default_chunk-len_last, :]\n",
    "        df_pool.append(new_df)\n",
    "        head = head + default_chunk - len_last+1\n",
    "    df_pool.append(d.loc[head:, :])\n",
    "    pool = Pool(8)\n",
    "    dfs = pool.map(linear_slope, df_pool)\n",
    "    pool.close()\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "\n",
    "def num_outliers(df):\n",
    "    new_df = df.groupby(\"object_id\").agg({\"flux\": [\"mean\", \"std\"]})\n",
    "    new_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in new_df.columns])\n",
    "    new_df[\"upper_sigma\"] = new_df[\"flux_mean\"] + new_df[\"flux_std\"]\n",
    "    new_df[\"upper_2sigma\"] = new_df[\"flux_mean\"] + 2 * new_df[\"flux_std\"]\n",
    "    new_df[\"lower_sigma\"] = new_df[\"flux_mean\"] - new_df[\"flux_std\"]\n",
    "    new_df[\"lower_2sigma\"] = new_df[\"flux_mean\"] - 2 * new_df[\"flux_std\"]\n",
    "    new_df.drop([\"flux_mean\", \"flux_std\"], axis=1, inplace=True)\n",
    "    new_df = pd.merge(df, new_df, how=\"left\", on=\"object_id\")\n",
    "    new_df[\"outside_sigma\"] = (\n",
    "        (new_df[\"flux\"] > new_df[\"upper_sigma\"]) |\n",
    "        (new_df[\"flux\"] < new_df[\"lower_sigma\"])).astype(int)\n",
    "    new_df[\"outside_2sigma\"] = (\n",
    "        (new_df[\"flux\"] > new_df[\"upper_2sigma\"]) |\n",
    "        (new_df[\"flux\"] < new_df[\"lower_2sigma\"])).astype(int)\n",
    "\n",
    "    return_df = new_df.groupby(\"object_id\").agg({\n",
    "        \"outside_sigma\": \"sum\",\n",
    "        \"outside_2sigma\": \"sum\"\n",
    "    })\n",
    "    return_df.reset_index(inplace=True)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8LKMf0xQChG8"
   },
   "outputs": [],
   "source": [
    "def get_full(df, meta):\n",
    "    agg_basic = basic(df)\n",
    "    agg_cluster = with_cluster(df)\n",
    "\n",
    "    cl_mean_diff = cluster_mean_diff(df)\n",
    "    ps_std_diff = passband_std_difference(df)\n",
    "    lin_sl = linear_slope(df)\n",
    "    num_out = num_outliers(df)\n",
    "\n",
    "    full = pd.merge(agg_basic, agg_cluster, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, cl_mean_diff, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, ps_std_diff, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, lin_sl, how=\"left\", on=\"object_id\")\n",
    "    full = pd.merge(full, num_out, how=\"left\", on=\"object_id\")\n",
    "\n",
    "    full = pd.merge(full, meta, how=\"left\", on=\"object_id\")\n",
    "    if \"target\" in full.columns:\n",
    "        full.drop(\"target\", axis=1, inplace=True)\n",
    "    return full\n",
    "\n",
    "\n",
    "def train_data(df, meta):\n",
    "    full = get_full(df, meta)\n",
    "    y = meta.target\n",
    "    classes = sorted(y.unique())\n",
    "    class_weight = {c: 1 for c in classes}\n",
    "\n",
    "    for c in [64, 15]:\n",
    "        class_weight[c] = 2\n",
    "    oof_df = full[[\"object_id\"]]\n",
    "    del full['object_id'], full['distmod'], full['hostgal_specz']\n",
    "    del full['ra'], full['decl'], full['gal_l'], full['gal_b'], full['ddf']\n",
    "    return full, y, classes, class_weight, oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Jeawd1ovCpWG",
    "outputId": "767f62f9-a28a-431e-feaa-8bd4b452376f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:04<00:00,  8.40it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 92.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 3s, sys: 4.57 s, total: 7min 7s\n",
      "Wall time: 6min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full, y, classes, class_weight, oof_df = train_data(train, meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsC3-yUuaQS7"
   },
   "outputs": [],
   "source": [
    "train_mean = full.mean(axis=0)\n",
    "full.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vHE2eKPaeur3"
   },
   "outputs": [],
   "source": [
    "# full.to_csv(\"full_train.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9Kcwi_EVe76_",
    "outputId": "6e267498-b599-4635-deeb-b1064c7caf54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: full_train.csv (deflated 55%)\n"
     ]
    }
   ],
   "source": [
    "# !zip full_train.csv.zip full_train.csv\n",
    "# !cp full_train.csv.zip /content/drive/My\\ Drive/plasticc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7V-R3l1IVFK"
   },
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HT3ihC7EHOjE"
   },
   "outputs": [],
   "source": [
    "def multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {\n",
    "        6: 1,\n",
    "        15: 2,\n",
    "        16: 1,\n",
    "        42: 1,\n",
    "        52: 1,\n",
    "        53: 1,\n",
    "        62: 1,\n",
    "        64: 2,\n",
    "        65: 1,\n",
    "        67: 1,\n",
    "        88: 1,\n",
    "        90: 1,\n",
    "        92: 1,\n",
    "        95: 1\n",
    "    }\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array(\n",
    "        [class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = -np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lgb_multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {\n",
    "        6: 1,\n",
    "        15: 2,\n",
    "        16: 1,\n",
    "        42: 1,\n",
    "        52: 1,\n",
    "        53: 1,\n",
    "        62: 1,\n",
    "        64: 2,\n",
    "        65: 1,\n",
    "        67: 1,\n",
    "        88: 1,\n",
    "        90: 1,\n",
    "        92: 1,\n",
    "        95: 1\n",
    "    }\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n",
    "\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array(\n",
    "        [class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = -np.sum(y_w) / np.sum(class_arr)\n",
    "    return 'wloss', loss, False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqLsbJ9UXUlD"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkxlccvqXV4V"
   },
   "outputs": [],
   "source": [
    "def save_importances(importances_):\n",
    "    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n",
    "    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    sns.barplot(\n",
    "        x='gain',\n",
    "        y='feature',\n",
    "        data=importances_.sort_values('mean_gain', ascending=False)[:250])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('importances.png')\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def save_cm(y, oof_preds, path):\n",
    "    unique_y = np.unique(y)\n",
    "    class_map = dict()\n",
    "    for i, val in enumerate(unique_y):\n",
    "        class_map[val] = i\n",
    "\n",
    "    y_map = np.zeros((y.shape[0], ))\n",
    "    y_map = np.array([class_map[val] for val in y])\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_map, np.argmax(oof_preds, axis=-1))\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    sample_sub = pd.read_csv(path)\n",
    "    class_names = list(sample_sub.columns[1:-1])\n",
    "    del sample_sub\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plot_confusion_matrix(\n",
    "        cnf_matrix,\n",
    "        classes=class_names,\n",
    "        normalize=True,\n",
    "        title='Confusion matrix')\n",
    "    plt.savefig(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJ5iBhWKXzCi"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1679
    },
    "colab_type": "code",
    "id": "05fOI0pgXvzy",
    "outputId": "1c09a6c6-1fde-4ca7-8079-0cbb8348f74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.790666\ttraining's wloss: 0.782197\tvalid_1's multi_logloss: 1.15701\tvalid_1's wloss: 0.963602\n",
      "[200]\ttraining's multi_logloss: 0.518249\ttraining's wloss: 0.506779\tvalid_1's multi_logloss: 0.929172\tvalid_1's wloss: 0.780153\n",
      "[300]\ttraining's multi_logloss: 0.39523\ttraining's wloss: 0.383376\tvalid_1's multi_logloss: 0.840354\tvalid_1's wloss: 0.73581\n",
      "[400]\ttraining's multi_logloss: 0.32126\ttraining's wloss: 0.309444\tvalid_1's multi_logloss: 0.79401\tvalid_1's wloss: 0.727857\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's multi_logloss: 0.320092\ttraining's wloss: 0.308276\tvalid_1's multi_logloss: 0.793086\tvalid_1's wloss: 0.727502\n",
      "0.7275017494599382\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.794842\ttraining's wloss: 0.788567\tvalid_1's multi_logloss: 1.14184\tvalid_1's wloss: 0.966297\n",
      "[200]\ttraining's multi_logloss: 0.519131\ttraining's wloss: 0.508868\tvalid_1's multi_logloss: 0.908561\tvalid_1's wloss: 0.780012\n",
      "[300]\ttraining's multi_logloss: 0.397215\ttraining's wloss: 0.386209\tvalid_1's multi_logloss: 0.818989\tvalid_1's wloss: 0.754035\n",
      "Early stopping, best iteration is:\n",
      "[316]\ttraining's multi_logloss: 0.383442\ttraining's wloss: 0.372315\tvalid_1's multi_logloss: 0.809666\tvalid_1's wloss: 0.753489\n",
      "0.7534890125651917\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.785581\ttraining's wloss: 0.777969\tvalid_1's multi_logloss: 1.16116\tvalid_1's wloss: 0.943981\n",
      "[200]\ttraining's multi_logloss: 0.513873\ttraining's wloss: 0.502708\tvalid_1's multi_logloss: 0.930969\tvalid_1's wloss: 0.744047\n",
      "[300]\ttraining's multi_logloss: 0.391198\ttraining's wloss: 0.379886\tvalid_1's multi_logloss: 0.842866\tvalid_1's wloss: 0.694578\n",
      "[400]\ttraining's multi_logloss: 0.31867\ttraining's wloss: 0.307685\tvalid_1's multi_logloss: 0.795117\tvalid_1's wloss: 0.681901\n",
      "[500]\ttraining's multi_logloss: 0.26793\ttraining's wloss: 0.257362\tvalid_1's multi_logloss: 0.7626\tvalid_1's wloss: 0.678793\n",
      "Early stopping, best iteration is:\n",
      "[491]\ttraining's multi_logloss: 0.272177\ttraining's wloss: 0.261534\tvalid_1's multi_logloss: 0.765391\tvalid_1's wloss: 0.678054\n",
      "0.6780542142350502\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.794951\ttraining's wloss: 0.786047\tvalid_1's multi_logloss: 1.1531\tvalid_1's wloss: 0.938104\n",
      "[200]\ttraining's multi_logloss: 0.520464\ttraining's wloss: 0.509488\tvalid_1's multi_logloss: 0.918189\tvalid_1's wloss: 0.73649\n",
      "[300]\ttraining's multi_logloss: 0.396016\ttraining's wloss: 0.38456\tvalid_1's multi_logloss: 0.823345\tvalid_1's wloss: 0.680099\n",
      "[400]\ttraining's multi_logloss: 0.319882\ttraining's wloss: 0.308587\tvalid_1's multi_logloss: 0.771524\tvalid_1's wloss: 0.664144\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's multi_logloss: 0.29559\ttraining's wloss: 0.284461\tvalid_1's multi_logloss: 0.755165\tvalid_1's wloss: 0.660532\n",
      "0.6605319004617792\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.791139\ttraining's wloss: 0.782632\tvalid_1's multi_logloss: 1.16006\tvalid_1's wloss: 0.981798\n",
      "[200]\ttraining's multi_logloss: 0.518725\ttraining's wloss: 0.507225\tvalid_1's multi_logloss: 0.919758\tvalid_1's wloss: 0.778701\n",
      "[300]\ttraining's multi_logloss: 0.397665\ttraining's wloss: 0.385984\tvalid_1's multi_logloss: 0.82152\tvalid_1's wloss: 0.721533\n",
      "[400]\ttraining's multi_logloss: 0.3253\ttraining's wloss: 0.313779\tvalid_1's multi_logloss: 0.76501\tvalid_1's wloss: 0.698227\n",
      "[500]\ttraining's multi_logloss: 0.274498\ttraining's wloss: 0.263425\tvalid_1's multi_logloss: 0.729654\tvalid_1's wloss: 0.694683\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttraining's multi_logloss: 0.270085\ttraining's wloss: 0.259028\tvalid_1's multi_logloss: 0.726727\tvalid_1's wloss: 0.694448\n",
      "0.6944480923616743\n",
      "MULTI WEIGHTED LOG LOSS : 0.70275 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 14,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': .9,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'reg_alpha': .01,\n",
    "    'reg_lambda': .01,\n",
    "    'min_split_gain': 0.01,\n",
    "    'min_child_weight': 10,\n",
    "    'n_estimators': 1000,\n",
    "    'silent': -1,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 3\n",
    "}\n",
    "\n",
    "# Compute weights\n",
    "w = y.value_counts()\n",
    "weights = {i: np.sum(w) / w[i] for i in w.index}\n",
    "oof_preds = np.zeros((len(full), np.unique(y).shape[0]))\n",
    "\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    trn_x, trn_y = full.iloc[trn_], y.iloc[trn_]\n",
    "    val_x, val_y = full.iloc[val_], y.iloc[val_]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(\n",
    "        trn_x,\n",
    "        trn_y,\n",
    "        eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "        eval_metric=lgb_multi_weighted_logloss,\n",
    "        verbose=100,\n",
    "        early_stopping_rounds=50,\n",
    "        sample_weight=trn_y.map(weights))\n",
    "    oof_preds[val_, :] = clf.predict_proba(\n",
    "        val_x, num_iteration=clf.best_iteration_)\n",
    "    print(multi_weighted_logloss(val_y, oof_preds[val_, :]))\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = full.columns\n",
    "    imp_df['gain'] = clf.feature_importances_\n",
    "    imp_df['fold'] = fold_ + 1\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "    clfs.append(clf)\n",
    "\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(\n",
    "    y_true=y, y_preds=oof_preds))\n",
    "save_importances(importances_=importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "UN8UkPi8YBcB",
    "outputId": "c3d939cf-bbb1-4b56-bd35-b59b96ce35e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    }
   ],
   "source": [
    "save_importances(importances_=importances)\n",
    "save_cm(y, oof_preds, data_dir + \"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mjd_size</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>flux_skew</th>\n",
       "      <th>flux_err_min</th>\n",
       "      <th>flux_err_max</th>\n",
       "      <th>flux_err_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>passband1</th>\n",
       "      <th>passband2</th>\n",
       "      <th>passband3</th>\n",
       "      <th>passband4</th>\n",
       "      <th>passband5</th>\n",
       "      <th>outside_sigma</th>\n",
       "      <th>outside_2sigma</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>mwebv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352</td>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-123.096998</td>\n",
       "      <td>-89.477524</td>\n",
       "      <td>394.109851</td>\n",
       "      <td>-0.349540</td>\n",
       "      <td>2.130510</td>\n",
       "      <td>12.845472</td>\n",
       "      <td>4.482743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>115</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350</td>\n",
       "      <td>-14.735178</td>\n",
       "      <td>14.770886</td>\n",
       "      <td>-1.423351</td>\n",
       "      <td>-0.873033</td>\n",
       "      <td>6.471144</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.639458</td>\n",
       "      <td>9.115748</td>\n",
       "      <td>2.359620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330</td>\n",
       "      <td>-19.159811</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>2.267434</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>8.022239</td>\n",
       "      <td>3.177854</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>11.281384</td>\n",
       "      <td>2.471061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>351</td>\n",
       "      <td>-15.494463</td>\n",
       "      <td>220.795212</td>\n",
       "      <td>8.909206</td>\n",
       "      <td>1.035895</td>\n",
       "      <td>27.558208</td>\n",
       "      <td>4.979826</td>\n",
       "      <td>0.567170</td>\n",
       "      <td>55.892746</td>\n",
       "      <td>2.555576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352</td>\n",
       "      <td>-16.543753</td>\n",
       "      <td>143.600189</td>\n",
       "      <td>7.145702</td>\n",
       "      <td>1.141288</td>\n",
       "      <td>20.051722</td>\n",
       "      <td>4.406298</td>\n",
       "      <td>0.695277</td>\n",
       "      <td>11.383690</td>\n",
       "      <td>2.753004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mjd_size     flux_min    flux_max   flux_mean  flux_median    flux_std  \\\n",
       "0       352 -1100.440063  660.626343 -123.096998   -89.477524  394.109851   \n",
       "1       350   -14.735178   14.770886   -1.423351    -0.873033    6.471144   \n",
       "2       330   -19.159811   47.310059    2.267434     0.409172    8.022239   \n",
       "3       351   -15.494463  220.795212    8.909206     1.035895   27.558208   \n",
       "4       352   -16.543753  143.600189    7.145702     1.141288   20.051722   \n",
       "\n",
       "   flux_skew  flux_err_min  flux_err_max  flux_err_mean  ...    passband1  \\\n",
       "0  -0.349540      2.130510     12.845472       4.482743  ...     0.003049   \n",
       "1   0.014989      0.639458      9.115748       2.359620  ...     0.002676   \n",
       "2   3.177854      0.695106     11.281384       2.471061  ...     0.002277   \n",
       "3   4.979826      0.567170     55.892746       2.555576  ...     0.002489   \n",
       "4   4.406298      0.695277     11.383690       2.753004  ...     0.003188   \n",
       "\n",
       "   passband2  passband3  passband4  passband5  outside_sigma  outside_2sigma  \\\n",
       "0   0.003407   0.003532   0.003279   0.002969            115              17   \n",
       "1   0.003259   0.002563   0.004220   0.001639            136               4   \n",
       "2   0.004382   0.003062   0.003725   0.003291             31              18   \n",
       "3   0.002071   0.002362   0.002687   0.003098             21              15   \n",
       "4   0.002722   0.002255   0.002364   0.002554             27              12   \n",
       "\n",
       "   hostgal_photoz  hostgal_photoz_err  mwebv  \n",
       "0          0.0000              0.0000  0.017  \n",
       "1          1.6267              0.2552  0.007  \n",
       "2          0.2262              0.0157  0.021  \n",
       "3          0.2813              1.1523  0.007  \n",
       "4          0.2415              0.0176  0.024  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUSDtkDkZa-S"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0OLVvaQY0si"
   },
   "outputs": [],
   "source": [
    "def predict_chunk(df_, clfs_, meta_, features, train_mean):\n",
    "    # Group by object id\n",
    "    df_ = add_cluster_multi(df_)\n",
    "    if i_c == 0:\n",
    "        df_.to_csv('test_with_cluster.csv', header=True, mode='a', index=False)\n",
    "    else:\n",
    "        df_.to_csv('test_with_cluster.csv', header=False, mode='a', index=False)\n",
    "    agg_ = get_full(df_, meta_)\n",
    "\n",
    "    full_test = agg_.fillna(0)\n",
    "    \n",
    "    if i_c == 0:\n",
    "        full_test.to_csv('full_test.csv', header=True, mode='a', index=False)\n",
    "    else:\n",
    "        full_test.to_csv('full_test.csv', header=False, mode='a', index=False)\n",
    "    # Make predictions\n",
    "    preds_ = None\n",
    "    for clf in clfs_:\n",
    "        if preds_ is None:\n",
    "            preds_ = clf.predict_proba(full_test[features]) / len(clfs_)\n",
    "        else:\n",
    "            preds_ += clf.predict_proba(full_test[features]) / len(clfs_)\n",
    "\n",
    "    # Compute preds_99 as the proba of class not being any of the others\n",
    "    # preds_99 = 0.1 gives 1.769\n",
    "    preds_99 = np.ones(preds_.shape[0])\n",
    "    for i in range(preds_.shape[1]):\n",
    "        preds_99 *= (1 - preds_[:, i])\n",
    "\n",
    "    # Create DataFrame from predictions\n",
    "    preds_df_ = pd.DataFrame(preds_, columns=['class_' + str(s) for s in clfs_[0].classes_])\n",
    "    preds_df_['object_id'] = full_test['object_id']\n",
    "    preds_df_['class_99'] = 0.14 * preds_99 / np.mean(preds_99) \n",
    "    return preds_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1162
    },
    "colab_type": "code",
    "id": "g7i-xAr5Zrn_",
    "outputId": "dd88a71b-5b07-4949-c45f-b637860566cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:16<00:00,  2.42it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:01<00:00, 24.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5da899554429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                              \u001b[0mmeta_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                              train_mean=train_mean)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi_c\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-a0e89e009101>\u001b[0m in \u001b[0;36mpredict_chunk\u001b[0;34m(df_, clfs_, meta_, features, train_mean)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_with_cluster.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0magg_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfull_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-197c4b97100d>\u001b[0m in \u001b[0;36mget_full\u001b[0;34m(df, meta)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcl_mean_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_mean_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mps_std_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpassband_std_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlin_sl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_slope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnum_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b90b7193b8e3>\u001b[0m in \u001b[0;36mlinear_slope\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassbands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             template.loc[template.query(\"object_id == @objid\").\n\u001b[0;32m--> 162\u001b[0;31m                          index, f\"passband{i}\"] = ps\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2847\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   2960\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resolvers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resolvers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2962\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/computation/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0meng_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_expr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massigner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/computation/engines.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_aligned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligned_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# make sure no names in resolvers and locals/globals clash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/computation/align.py\u001b[0m in \u001b[0;36m_align\u001b[0;34m(terms)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# perform the main alignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/computation/align.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(terms)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_result_type_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mterm_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/computation/align.py\u001b[0m in \u001b[0;36m_align_core\u001b[0;34m(terms)\u001b[0m\n\u001b[1;32m     64\u001b[0m                   if hasattr(term.value, 'axes')]\n\u001b[1;32m     65\u001b[0m     \u001b[0mterm_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterm_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# initial axes are the axes of the largest-axis'd term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, dtype)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# Input is now list-like, so rely on \"standard\" construction:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# Now we just make sure the order is respected, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_ensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   4972\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4974\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;31m# other iterable of some kind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \"\"\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                         return cls._try_convert_to_int_index(\n\u001b[0;32m--> 393\u001b[0;31m                             subarr, copy, name, dtype)\n\u001b[0m\u001b[1;32m    394\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_try_convert_to_int_index\u001b[0;34m(cls, data, copy, name, dtype)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mInt64Index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOverflowError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "meta_test = pd.read_csv(data_dir + '/test_set_metadata.csv')\n",
    "# meta_test.set_index('object_id',inplace=True)\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "chunks = 10000000\n",
    "remain_df = None\n",
    "\n",
    "for i_c, df in enumerate(pd.read_csv(data_dir + '/test_set.csv', chunksize=chunks, iterator=True)):\n",
    "    # Check object_ids\n",
    "    # I believe np.unique keeps the order of group_ids as they appear in the file\n",
    "    unique_ids = np.unique(df['object_id'])\n",
    "    new_remain_df = df.loc[df['object_id'] == unique_ids[-1]].copy()\n",
    "    if remain_df is None:\n",
    "        df = df.loc[df['object_id'].isin(unique_ids[:-1])]\n",
    "    else:\n",
    "        df = pd.concat([remain_df, df.loc[df['object_id'].isin(unique_ids[:-1])]], axis=0)\n",
    "    # Create remaining samples df\n",
    "    remain_df = new_remain_df\n",
    "    preds_df = predict_chunk(df_=df,\n",
    "                             clfs_=clfs,\n",
    "                             meta_=meta_test,\n",
    "                             features=full.columns,\n",
    "                             train_mean=train_mean)\n",
    "\n",
    "    if i_c == 0:\n",
    "        preds_df.to_csv('predictions.csv', header=True, mode='a', index=False)\n",
    "    else:\n",
    "        preds_df.to_csv('predictions.csv', header=False, mode='a', index=False)\n",
    "\n",
    "    del preds_df\n",
    "    gc.collect()\n",
    "    \n",
    "    print('%15d done in %5.1f minutes' % (chunks * (i_c + 1), (time.time() - start) / 60), flush=True)\n",
    "\n",
    "# Compute last object in remain_df\n",
    "preds_df = predict_chunk(df_=remain_df,\n",
    "                         clfs_=clfs,\n",
    "                         meta_=meta_test,\n",
    "                         features=full_train.columns,\n",
    "                         train_mean=train_mean)\n",
    "\n",
    "preds_df.to_csv('predictions.csv', header=False, mode='a', index=False)\n",
    "#!zip test_with_cluster.csv.zip test_with_cluster.csv\n",
    "#!zip full_test.csv.zip full_test.csv\n",
    "#!cp test_with_cluster.csv.zip /content/drive/My\\ Drive/plasticc/\n",
    "#!cp full_test.csv.zip /content/drive/My\\ Drive/plasticc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zcV7Svg9bfSL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PLAsTiCC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
